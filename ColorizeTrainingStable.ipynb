{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stable Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTES:  \n",
    "* This is \"NoGAN\" based training, described in the DeOldify readme.\n",
    "* This model prioritizes stable and reliable renderings.  It does particularly well on portraits and landscapes.  It's not as colorful as the artistic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install fiftyone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DeviceId.GPU0: 0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NOTE:  This must be the first call in order to work properly!\n",
    "from deoldify import device\n",
    "from deoldify.device_id import DeviceId\n",
    "#choices:  CPU, GPU0...GPU7\n",
    "device.set(device=DeviceId.GPU0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Mar  4 19:29:53 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.103.01   Driver Version: 470.103.01   CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:09:00.0  On |                  N/A |\n",
      "|  6%   45C    P8    11W / 250W |     38MiB / 11175MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1304      G   /usr/lib/xorg/Xorg                 36MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fastai\n",
    "from fastai import *\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks.tensorboard import *\n",
    "from fastai.vision.gan import *\n",
    "from deoldify.generators import *\n",
    "from deoldify.critics import *\n",
    "from deoldify.dataset import *\n",
    "from deoldify.loss import *\n",
    "from deoldify.save import *\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from PIL import ImageFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['NUMEXPR_MAX_THREADS'] = '24'\n",
    "path = Path('data/imagenet/ILSVRC/Data/CLS-LOC')\n",
    "path_hr = path\n",
    "path_lr = path/'bandw'\n",
    "\n",
    "import fiftyone as fo\n",
    "\n",
    "# Customize where zoo datasets are downloaded\n",
    "fo.config.dataset_zoo_dir = path\n",
    "\n",
    "\n",
    "\n",
    "proj_id = 'StableModel'\n",
    "\n",
    "gen_name = proj_id + '_gen'\n",
    "pre_gen_name = gen_name + '_0'\n",
    "crit_name = proj_id + '_crit'\n",
    "\n",
    "name_gen = proj_id + '_image_gen'\n",
    "path_gen = path/name_gen\n",
    "\n",
    "TENSORBOARD_PATH = Path('data/tensorboard/' + proj_id)\n",
    "\n",
    "nf_factor = 2\n",
    "pct_start = 1e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(bs:int, sz:int, keep_pct:float):\n",
    "    return get_colorize_data(sz=sz, bs=bs, crappy_path=path_lr, good_path=path_hr, \n",
    "                             random_seed=None, keep_pct=keep_pct)\n",
    "\n",
    "def get_crit_data(classes, bs, sz):\n",
    "    src = ImageList.from_folder(path, include=classes, recurse=True).split_by_rand_pct(0.1, seed=42)\n",
    "    ll = src.label_from_folder(classes=classes)\n",
    "    data = (ll.transform(get_transforms(max_zoom=2.), size=sz)\n",
    "           .databunch(bs=bs).normalize(imagenet_stats))\n",
    "    return data\n",
    "\n",
    "def create_training_images(fn,i):\n",
    "    dest = path_lr/fn.relative_to(path_hr)\n",
    "    dest.parent.mkdir(parents=True, exist_ok=True)\n",
    "    img = PIL.Image.open(fn).convert('LA').convert('RGB')\n",
    "    img.save(dest)  \n",
    "    \n",
    "def save_preds(dl):\n",
    "    i=0\n",
    "    names = dl.dataset.items\n",
    "    \n",
    "    for b in dl:\n",
    "        preds = learn_gen.pred_batch(batch=b, reconstruct=True)\n",
    "        for o in preds:\n",
    "            o.save(path_gen/names[i].name)\n",
    "            i += 1\n",
    "    \n",
    "def save_gen_images():\n",
    "    if path_gen.exists(): shutil.rmtree(path_gen)\n",
    "    path_gen.mkdir(exist_ok=True)\n",
    "    data_gen = get_data(bs=bs, sz=sz, keep_pct=0.085)\n",
    "    save_preds(data_gen.fix_dl)\n",
    "    PIL.Image.open(path_gen.ls()[0])\n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create black and white training images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only runs if the directory isn't already created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not path_lr.exists():\n",
    "    il = ImageList.from_folder(path_hr)\n",
    "    parallel(create_training_images, il.items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-train generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE\n",
    "Most of the training takes place here in pretraining for NoGAN.  The goal here is to take the generator as far as possible with conventional training, as that is much easier to control and obtain glitch-free results compared to GAN training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 64px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=44\n",
    "sz=64\n",
    "keep_pct=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen = get_data(bs=bs, sz=sz, keep_pct=keep_pct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "learn_gen = gen_learner_wide(data=data_gen, gen_loss=FeatureLoss(), nf_factor=nf_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_gen.callback_fns.append(partial(ImageGenTensorboardWriter, base_dir=TENSORBOARD_PATH, name='GenPre'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='1135' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1135 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmv/DeOldify/deoldify/unet.py:202: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if ssh != up_out.shape[-2:]:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurs, No graph saved\n",
      "Checking if it's onnx problem...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmv/miniconda3/envs/deoldify/lib/python3.7/site-packages/torch/onnx/utils.py:501: UserWarning: ONNX export failed on ATen operator reshape because torch.onnx.symbolic.reshape does not exist\n",
      "  .format(op_name, op_name))\n",
      "/home/dmv/miniconda3/envs/deoldify/lib/python3.7/site-packages/torch/onnx/utils.py:501: UserWarning: ONNX export failed on ATen operator mv because torch.onnx.symbolic.mv does not exist\n",
      "  .format(op_name, op_name))\n",
      "/home/dmv/miniconda3/envs/deoldify/lib/python3.7/site-packages/torch/onnx/utils.py:501: UserWarning: ONNX export failed on ATen operator dot because torch.onnx.symbolic.dot does not exist\n",
      "  .format(op_name, op_name))\n",
      "/home/dmv/miniconda3/envs/deoldify/lib/python3.7/site-packages/torch/onnx/symbolic.py:131: UserWarning: ONNX export failed on dim because ONNX and PyTorch use different strategies to split the input. not supported\n",
      "  warnings.warn(\"ONNX export failed on \" + op + \" because \" + msg + \" not supported\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%0 : Float(1, 3, 64, 64)\n",
      "      %1 : Float(64, 3, 7, 7)\n",
      "      %2 : Float(64)\n",
      "      %3 : Float(64)\n",
      "      %4 : Float(64)\n",
      "      %5 : Float(64)\n",
      "      %6 : Long()\n",
      "      %7 : Float(64, 64, 1, 1)\n",
      "      %8 : Float(64)\n",
      "      %9 : Float(64)\n",
      "      %10 : Float(64)\n",
      "      %11 : Float(64)\n",
      "      %12 : Long()\n",
      "      %13 : Float(64, 64, 3, 3)\n",
      "      %14 : Float(64)\n",
      "      %15 : Float(64)\n",
      "      %16 : Float(64)\n",
      "      %17 : Float(64)\n",
      "      %18 : Long()\n",
      "      %19 : Float(256, 64, 1, 1)\n",
      "      %20 : Float(256)\n",
      "      %21 : Float(256)\n",
      "      %22 : Float(256)\n",
      "      %23 : Float(256)\n",
      "      %24 : Long()\n",
      "      %25 : Float(256, 64, 1, 1)\n",
      "      %26 : Float(256)\n",
      "      %27 : Float(256)\n",
      "      %28 : Float(256)\n",
      "      %29 : Float(256)\n",
      "      %30 : Long()\n",
      "      %31 : Float(64, 256, 1, 1)\n",
      "      %32 : Float(64)\n",
      "      %33 : Float(64)\n",
      "      %34 : Float(64)\n",
      "      %35 : Float(64)\n",
      "      %36 : Long()\n",
      "      %37 : Float(64, 64, 3, 3)\n",
      "      %38 : Float(64)\n",
      "      %39 : Float(64)\n",
      "      %40 : Float(64)\n",
      "      %41 : Float(64)\n",
      "      %42 : Long()\n",
      "      %43 : Float(256, 64, 1, 1)\n",
      "      %44 : Float(256)\n",
      "      %45 : Float(256)\n",
      "      %46 : Float(256)\n",
      "      %47 : Float(256)\n",
      "      %48 : Long()\n",
      "      %49 : Float(64, 256, 1, 1)\n",
      "      %50 : Float(64)\n",
      "      %51 : Float(64)\n",
      "      %52 : Float(64)\n",
      "      %53 : Float(64)\n",
      "      %54 : Long()\n",
      "      %55 : Float(64, 64, 3, 3)\n",
      "      %56 : Float(64)\n",
      "      %57 : Float(64)\n",
      "      %58 : Float(64)\n",
      "      %59 : Float(64)\n",
      "      %60 : Long()\n",
      "      %61 : Float(256, 64, 1, 1)\n",
      "      %62 : Float(256)\n",
      "      %63 : Float(256)\n",
      "      %64 : Float(256)\n",
      "      %65 : Float(256)\n",
      "      %66 : Long()\n",
      "      %67 : Float(128, 256, 1, 1)\n",
      "      %68 : Float(128)\n",
      "      %69 : Float(128)\n",
      "      %70 : Float(128)\n",
      "      %71 : Float(128)\n",
      "      %72 : Long()\n",
      "      %73 : Float(128, 128, 3, 3)\n",
      "      %74 : Float(128)\n",
      "      %75 : Float(128)\n",
      "      %76 : Float(128)\n",
      "      %77 : Float(128)\n",
      "      %78 : Long()\n",
      "      %79 : Float(512, 128, 1, 1)\n",
      "      %80 : Float(512)\n",
      "      %81 : Float(512)\n",
      "      %82 : Float(512)\n",
      "      %83 : Float(512)\n",
      "      %84 : Long()\n",
      "      %85 : Float(512, 256, 1, 1)\n",
      "      %86 : Float(512)\n",
      "      %87 : Float(512)\n",
      "      %88 : Float(512)\n",
      "      %89 : Float(512)\n",
      "      %90 : Long()\n",
      "      %91 : Float(128, 512, 1, 1)\n",
      "      %92 : Float(128)\n",
      "      %93 : Float(128)\n",
      "      %94 : Float(128)\n",
      "      %95 : Float(128)\n",
      "      %96 : Long()\n",
      "      %97 : Float(128, 128, 3, 3)\n",
      "      %98 : Float(128)\n",
      "      %99 : Float(128)\n",
      "      %100 : Float(128)\n",
      "      %101 : Float(128)\n",
      "      %102 : Long()\n",
      "      %103 : Float(512, 128, 1, 1)\n",
      "      %104 : Float(512)\n",
      "      %105 : Float(512)\n",
      "      %106 : Float(512)\n",
      "      %107 : Float(512)\n",
      "      %108 : Long()\n",
      "      %109 : Float(128, 512, 1, 1)\n",
      "      %110 : Float(128)\n",
      "      %111 : Float(128)\n",
      "      %112 : Float(128)\n",
      "      %113 : Float(128)\n",
      "      %114 : Long()\n",
      "      %115 : Float(128, 128, 3, 3)\n",
      "      %116 : Float(128)\n",
      "      %117 : Float(128)\n",
      "      %118 : Float(128)\n",
      "      %119 : Float(128)\n",
      "      %120 : Long()\n",
      "      %121 : Float(512, 128, 1, 1)\n",
      "      %122 : Float(512)\n",
      "      %123 : Float(512)\n",
      "      %124 : Float(512)\n",
      "      %125 : Float(512)\n",
      "      %126 : Long()\n",
      "      %127 : Float(128, 512, 1, 1)\n",
      "      %128 : Float(128)\n",
      "      %129 : Float(128)\n",
      "      %130 : Float(128)\n",
      "      %131 : Float(128)\n",
      "      %132 : Long()\n",
      "      %133 : Float(128, 128, 3, 3)\n",
      "      %134 : Float(128)\n",
      "      %135 : Float(128)\n",
      "      %136 : Float(128)\n",
      "      %137 : Float(128)\n",
      "      %138 : Long()\n",
      "      %139 : Float(512, 128, 1, 1)\n",
      "      %140 : Float(512)\n",
      "      %141 : Float(512)\n",
      "      %142 : Float(512)\n",
      "      %143 : Float(512)\n",
      "      %144 : Long()\n",
      "      %145 : Float(256, 512, 1, 1)\n",
      "      %146 : Float(256)\n",
      "      %147 : Float(256)\n",
      "      %148 : Float(256)\n",
      "      %149 : Float(256)\n",
      "      %150 : Long()\n",
      "      %151 : Float(256, 256, 3, 3)\n",
      "      %152 : Float(256)\n",
      "      %153 : Float(256)\n",
      "      %154 : Float(256)\n",
      "      %155 : Float(256)\n",
      "      %156 : Long()\n",
      "      %157 : Float(1024, 256, 1, 1)\n",
      "      %158 : Float(1024)\n",
      "      %159 : Float(1024)\n",
      "      %160 : Float(1024)\n",
      "      %161 : Float(1024)\n",
      "      %162 : Long()\n",
      "      %163 : Float(1024, 512, 1, 1)\n",
      "      %164 : Float(1024)\n",
      "      %165 : Float(1024)\n",
      "      %166 : Float(1024)\n",
      "      %167 : Float(1024)\n",
      "      %168 : Long()\n",
      "      %169 : Float(256, 1024, 1, 1)\n",
      "      %170 : Float(256)\n",
      "      %171 : Float(256)\n",
      "      %172 : Float(256)\n",
      "      %173 : Float(256)\n",
      "      %174 : Long()\n",
      "      %175 : Float(256, 256, 3, 3)\n",
      "      %176 : Float(256)\n",
      "      %177 : Float(256)\n",
      "      %178 : Float(256)\n",
      "      %179 : Float(256)\n",
      "      %180 : Long()\n",
      "      %181 : Float(1024, 256, 1, 1)\n",
      "      %182 : Float(1024)\n",
      "      %183 : Float(1024)\n",
      "      %184 : Float(1024)\n",
      "      %185 : Float(1024)\n",
      "      %186 : Long()\n",
      "      %187 : Float(256, 1024, 1, 1)\n",
      "      %188 : Float(256)\n",
      "      %189 : Float(256)\n",
      "      %190 : Float(256)\n",
      "      %191 : Float(256)\n",
      "      %192 : Long()\n",
      "      %193 : Float(256, 256, 3, 3)\n",
      "      %194 : Float(256)\n",
      "      %195 : Float(256)\n",
      "      %196 : Float(256)\n",
      "      %197 : Float(256)\n",
      "      %198 : Long()\n",
      "      %199 : Float(1024, 256, 1, 1)\n",
      "      %200 : Float(1024)\n",
      "      %201 : Float(1024)\n",
      "      %202 : Float(1024)\n",
      "      %203 : Float(1024)\n",
      "      %204 : Long()\n",
      "      %205 : Float(256, 1024, 1, 1)\n",
      "      %206 : Float(256)\n",
      "      %207 : Float(256)\n",
      "      %208 : Float(256)\n",
      "      %209 : Float(256)\n",
      "      %210 : Long()\n",
      "      %211 : Float(256, 256, 3, 3)\n",
      "      %212 : Float(256)\n",
      "      %213 : Float(256)\n",
      "      %214 : Float(256)\n",
      "      %215 : Float(256)\n",
      "      %216 : Long()\n",
      "      %217 : Float(1024, 256, 1, 1)\n",
      "      %218 : Float(1024)\n",
      "      %219 : Float(1024)\n",
      "      %220 : Float(1024)\n",
      "      %221 : Float(1024)\n",
      "      %222 : Long()\n",
      "      %223 : Float(256, 1024, 1, 1)\n",
      "      %224 : Float(256)\n",
      "      %225 : Float(256)\n",
      "      %226 : Float(256)\n",
      "      %227 : Float(256)\n",
      "      %228 : Long()\n",
      "      %229 : Float(256, 256, 3, 3)\n",
      "      %230 : Float(256)\n",
      "      %231 : Float(256)\n",
      "      %232 : Float(256)\n",
      "      %233 : Float(256)\n",
      "      %234 : Long()\n",
      "      %235 : Float(1024, 256, 1, 1)\n",
      "      %236 : Float(1024)\n",
      "      %237 : Float(1024)\n",
      "      %238 : Float(1024)\n",
      "      %239 : Float(1024)\n",
      "      %240 : Long()\n",
      "      %241 : Float(256, 1024, 1, 1)\n",
      "      %242 : Float(256)\n",
      "      %243 : Float(256)\n",
      "      %244 : Float(256)\n",
      "      %245 : Float(256)\n",
      "      %246 : Long()\n",
      "      %247 : Float(256, 256, 3, 3)\n",
      "      %248 : Float(256)\n",
      "      %249 : Float(256)\n",
      "      %250 : Float(256)\n",
      "      %251 : Float(256)\n",
      "      %252 : Long()\n",
      "      %253 : Float(1024, 256, 1, 1)\n",
      "      %254 : Float(1024)\n",
      "      %255 : Float(1024)\n",
      "      %256 : Float(1024)\n",
      "      %257 : Float(1024)\n",
      "      %258 : Long()\n",
      "      %259 : Float(256, 1024, 1, 1)\n",
      "      %260 : Float(256)\n",
      "      %261 : Float(256)\n",
      "      %262 : Float(256)\n",
      "      %263 : Float(256)\n",
      "      %264 : Long()\n",
      "      %265 : Float(256, 256, 3, 3)\n",
      "      %266 : Float(256)\n",
      "      %267 : Float(256)\n",
      "      %268 : Float(256)\n",
      "      %269 : Float(256)\n",
      "      %270 : Long()\n",
      "      %271 : Float(1024, 256, 1, 1)\n",
      "      %272 : Float(1024)\n",
      "      %273 : Float(1024)\n",
      "      %274 : Float(1024)\n",
      "      %275 : Float(1024)\n",
      "      %276 : Long()\n",
      "      %277 : Float(256, 1024, 1, 1)\n",
      "      %278 : Float(256)\n",
      "      %279 : Float(256)\n",
      "      %280 : Float(256)\n",
      "      %281 : Float(256)\n",
      "      %282 : Long()\n",
      "      %283 : Float(256, 256, 3, 3)\n",
      "      %284 : Float(256)\n",
      "      %285 : Float(256)\n",
      "      %286 : Float(256)\n",
      "      %287 : Float(256)\n",
      "      %288 : Long()\n",
      "      %289 : Float(1024, 256, 1, 1)\n",
      "      %290 : Float(1024)\n",
      "      %291 : Float(1024)\n",
      "      %292 : Float(1024)\n",
      "      %293 : Float(1024)\n",
      "      %294 : Long()\n",
      "      %295 : Float(256, 1024, 1, 1)\n",
      "      %296 : Float(256)\n",
      "      %297 : Float(256)\n",
      "      %298 : Float(256)\n",
      "      %299 : Float(256)\n",
      "      %300 : Long()\n",
      "      %301 : Float(256, 256, 3, 3)\n",
      "      %302 : Float(256)\n",
      "      %303 : Float(256)\n",
      "      %304 : Float(256)\n",
      "      %305 : Float(256)\n",
      "      %306 : Long()\n",
      "      %307 : Float(1024, 256, 1, 1)\n",
      "      %308 : Float(1024)\n",
      "      %309 : Float(1024)\n",
      "      %310 : Float(1024)\n",
      "      %311 : Float(1024)\n",
      "      %312 : Long()\n",
      "      %313 : Float(256, 1024, 1, 1)\n",
      "      %314 : Float(256)\n",
      "      %315 : Float(256)\n",
      "      %316 : Float(256)\n",
      "      %317 : Float(256)\n",
      "      %318 : Long()\n",
      "      %319 : Float(256, 256, 3, 3)\n",
      "      %320 : Float(256)\n",
      "      %321 : Float(256)\n",
      "      %322 : Float(256)\n",
      "      %323 : Float(256)\n",
      "      %324 : Long()\n",
      "      %325 : Float(1024, 256, 1, 1)\n",
      "      %326 : Float(1024)\n",
      "      %327 : Float(1024)\n",
      "      %328 : Float(1024)\n",
      "      %329 : Float(1024)\n",
      "      %330 : Long()\n",
      "      %331 : Float(256, 1024, 1, 1)\n",
      "      %332 : Float(256)\n",
      "      %333 : Float(256)\n",
      "      %334 : Float(256)\n",
      "      %335 : Float(256)\n",
      "      %336 : Long()\n",
      "      %337 : Float(256, 256, 3, 3)\n",
      "      %338 : Float(256)\n",
      "      %339 : Float(256)\n",
      "      %340 : Float(256)\n",
      "      %341 : Float(256)\n",
      "      %342 : Long()\n",
      "      %343 : Float(1024, 256, 1, 1)\n",
      "      %344 : Float(1024)\n",
      "      %345 : Float(1024)\n",
      "      %346 : Float(1024)\n",
      "      %347 : Float(1024)\n",
      "      %348 : Long()\n",
      "      %349 : Float(256, 1024, 1, 1)\n",
      "      %350 : Float(256)\n",
      "      %351 : Float(256)\n",
      "      %352 : Float(256)\n",
      "      %353 : Float(256)\n",
      "      %354 : Long()\n",
      "      %355 : Float(256, 256, 3, 3)\n",
      "      %356 : Float(256)\n",
      "      %357 : Float(256)\n",
      "      %358 : Float(256)\n",
      "      %359 : Float(256)\n",
      "      %360 : Long()\n",
      "      %361 : Float(1024, 256, 1, 1)\n",
      "      %362 : Float(1024)\n",
      "      %363 : Float(1024)\n",
      "      %364 : Float(1024)\n",
      "      %365 : Float(1024)\n",
      "      %366 : Long()\n",
      "      %367 : Float(256, 1024, 1, 1)\n",
      "      %368 : Float(256)\n",
      "      %369 : Float(256)\n",
      "      %370 : Float(256)\n",
      "      %371 : Float(256)\n",
      "      %372 : Long()\n",
      "      %373 : Float(256, 256, 3, 3)\n",
      "      %374 : Float(256)\n",
      "      %375 : Float(256)\n",
      "      %376 : Float(256)\n",
      "      %377 : Float(256)\n",
      "      %378 : Long()\n",
      "      %379 : Float(1024, 256, 1, 1)\n",
      "      %380 : Float(1024)\n",
      "      %381 : Float(1024)\n",
      "      %382 : Float(1024)\n",
      "      %383 : Float(1024)\n",
      "      %384 : Long()\n",
      "      %385 : Float(256, 1024, 1, 1)\n",
      "      %386 : Float(256)\n",
      "      %387 : Float(256)\n",
      "      %388 : Float(256)\n",
      "      %389 : Float(256)\n",
      "      %390 : Long()\n",
      "      %391 : Float(256, 256, 3, 3)\n",
      "      %392 : Float(256)\n",
      "      %393 : Float(256)\n",
      "      %394 : Float(256)\n",
      "      %395 : Float(256)\n",
      "      %396 : Long()\n",
      "      %397 : Float(1024, 256, 1, 1)\n",
      "      %398 : Float(1024)\n",
      "      %399 : Float(1024)\n",
      "      %400 : Float(1024)\n",
      "      %401 : Float(1024)\n",
      "      %402 : Long()\n",
      "      %403 : Float(256, 1024, 1, 1)\n",
      "      %404 : Float(256)\n",
      "      %405 : Float(256)\n",
      "      %406 : Float(256)\n",
      "      %407 : Float(256)\n",
      "      %408 : Long()\n",
      "      %409 : Float(256, 256, 3, 3)\n",
      "      %410 : Float(256)\n",
      "      %411 : Float(256)\n",
      "      %412 : Float(256)\n",
      "      %413 : Float(256)\n",
      "      %414 : Long()\n",
      "      %415 : Float(1024, 256, 1, 1)\n",
      "      %416 : Float(1024)\n",
      "      %417 : Float(1024)\n",
      "      %418 : Float(1024)\n",
      "      %419 : Float(1024)\n",
      "      %420 : Long()\n",
      "      %421 : Float(256, 1024, 1, 1)\n",
      "      %422 : Float(256)\n",
      "      %423 : Float(256)\n",
      "      %424 : Float(256)\n",
      "      %425 : Float(256)\n",
      "      %426 : Long()\n",
      "      %427 : Float(256, 256, 3, 3)\n",
      "      %428 : Float(256)\n",
      "      %429 : Float(256)\n",
      "      %430 : Float(256)\n",
      "      %431 : Float(256)\n",
      "      %432 : Long()\n",
      "      %433 : Float(1024, 256, 1, 1)\n",
      "      %434 : Float(1024)\n",
      "      %435 : Float(1024)\n",
      "      %436 : Float(1024)\n",
      "      %437 : Float(1024)\n",
      "      %438 : Long()\n",
      "      %439 : Float(256, 1024, 1, 1)\n",
      "      %440 : Float(256)\n",
      "      %441 : Float(256)\n",
      "      %442 : Float(256)\n",
      "      %443 : Float(256)\n",
      "      %444 : Long()\n",
      "      %445 : Float(256, 256, 3, 3)\n",
      "      %446 : Float(256)\n",
      "      %447 : Float(256)\n",
      "      %448 : Float(256)\n",
      "      %449 : Float(256)\n",
      "      %450 : Long()\n",
      "      %451 : Float(1024, 256, 1, 1)\n",
      "      %452 : Float(1024)\n",
      "      %453 : Float(1024)\n",
      "      %454 : Float(1024)\n",
      "      %455 : Float(1024)\n",
      "      %456 : Long()\n",
      "      %457 : Float(256, 1024, 1, 1)\n",
      "      %458 : Float(256)\n",
      "      %459 : Float(256)\n",
      "      %460 : Float(256)\n",
      "      %461 : Float(256)\n",
      "      %462 : Long()\n",
      "      %463 : Float(256, 256, 3, 3)\n",
      "      %464 : Float(256)\n",
      "      %465 : Float(256)\n",
      "      %466 : Float(256)\n",
      "      %467 : Float(256)\n",
      "      %468 : Long()\n",
      "      %469 : Float(1024, 256, 1, 1)\n",
      "      %470 : Float(1024)\n",
      "      %471 : Float(1024)\n",
      "      %472 : Float(1024)\n",
      "      %473 : Float(1024)\n",
      "      %474 : Long()\n",
      "      %475 : Float(256, 1024, 1, 1)\n",
      "      %476 : Float(256)\n",
      "      %477 : Float(256)\n",
      "      %478 : Float(256)\n",
      "      %479 : Float(256)\n",
      "      %480 : Long()\n",
      "      %481 : Float(256, 256, 3, 3)\n",
      "      %482 : Float(256)\n",
      "      %483 : Float(256)\n",
      "      %484 : Float(256)\n",
      "      %485 : Float(256)\n",
      "      %486 : Long()\n",
      "      %487 : Float(1024, 256, 1, 1)\n",
      "      %488 : Float(1024)\n",
      "      %489 : Float(1024)\n",
      "      %490 : Float(1024)\n",
      "      %491 : Float(1024)\n",
      "      %492 : Long()\n",
      "      %493 : Float(256, 1024, 1, 1)\n",
      "      %494 : Float(256)\n",
      "      %495 : Float(256)\n",
      "      %496 : Float(256)\n",
      "      %497 : Float(256)\n",
      "      %498 : Long()\n",
      "      %499 : Float(256, 256, 3, 3)\n",
      "      %500 : Float(256)\n",
      "      %501 : Float(256)\n",
      "      %502 : Float(256)\n",
      "      %503 : Float(256)\n",
      "      %504 : Long()\n",
      "      %505 : Float(1024, 256, 1, 1)\n",
      "      %506 : Float(1024)\n",
      "      %507 : Float(1024)\n",
      "      %508 : Float(1024)\n",
      "      %509 : Float(1024)\n",
      "      %510 : Long()\n",
      "      %511 : Float(256, 1024, 1, 1)\n",
      "      %512 : Float(256)\n",
      "      %513 : Float(256)\n",
      "      %514 : Float(256)\n",
      "      %515 : Float(256)\n",
      "      %516 : Long()\n",
      "      %517 : Float(256, 256, 3, 3)\n",
      "      %518 : Float(256)\n",
      "      %519 : Float(256)\n",
      "      %520 : Float(256)\n",
      "      %521 : Float(256)\n",
      "      %522 : Long()\n",
      "      %523 : Float(1024, 256, 1, 1)\n",
      "      %524 : Float(1024)\n",
      "      %525 : Float(1024)\n",
      "      %526 : Float(1024)\n",
      "      %527 : Float(1024)\n",
      "      %528 : Long()\n",
      "      %529 : Float(256, 1024, 1, 1)\n",
      "      %530 : Float(256)\n",
      "      %531 : Float(256)\n",
      "      %532 : Float(256)\n",
      "      %533 : Float(256)\n",
      "      %534 : Long()\n",
      "      %535 : Float(256, 256, 3, 3)\n",
      "      %536 : Float(256)\n",
      "      %537 : Float(256)\n",
      "      %538 : Float(256)\n",
      "      %539 : Float(256)\n",
      "      %540 : Long()\n",
      "      %541 : Float(1024, 256, 1, 1)\n",
      "      %542 : Float(1024)\n",
      "      %543 : Float(1024)\n",
      "      %544 : Float(1024)\n",
      "      %545 : Float(1024)\n",
      "      %546 : Long()\n",
      "      %547 : Float(256, 1024, 1, 1)\n",
      "      %548 : Float(256)\n",
      "      %549 : Float(256)\n",
      "      %550 : Float(256)\n",
      "      %551 : Float(256)\n",
      "      %552 : Long()\n",
      "      %553 : Float(256, 256, 3, 3)\n",
      "      %554 : Float(256)\n",
      "      %555 : Float(256)\n",
      "      %556 : Float(256)\n",
      "      %557 : Float(256)\n",
      "      %558 : Long()\n",
      "      %559 : Float(1024, 256, 1, 1)\n",
      "      %560 : Float(1024)\n",
      "      %561 : Float(1024)\n",
      "      %562 : Float(1024)\n",
      "      %563 : Float(1024)\n",
      "      %564 : Long()\n",
      "      %565 : Float(512, 1024, 1, 1)\n",
      "      %566 : Float(512)\n",
      "      %567 : Float(512)\n",
      "      %568 : Float(512)\n",
      "      %569 : Float(512)\n",
      "      %570 : Long()\n",
      "      %571 : Float(512, 512, 3, 3)\n",
      "      %572 : Float(512)\n",
      "      %573 : Float(512)\n",
      "      %574 : Float(512)\n",
      "      %575 : Float(512)\n",
      "      %576 : Long()\n",
      "      %577 : Float(2048, 512, 1, 1)\n",
      "      %578 : Float(2048)\n",
      "      %579 : Float(2048)\n",
      "      %580 : Float(2048)\n",
      "      %581 : Float(2048)\n",
      "      %582 : Long()\n",
      "      %583 : Float(2048, 1024, 1, 1)\n",
      "      %584 : Float(2048)\n",
      "      %585 : Float(2048)\n",
      "      %586 : Float(2048)\n",
      "      %587 : Float(2048)\n",
      "      %588 : Long()\n",
      "      %589 : Float(512, 2048, 1, 1)\n",
      "      %590 : Float(512)\n",
      "      %591 : Float(512)\n",
      "      %592 : Float(512)\n",
      "      %593 : Float(512)\n",
      "      %594 : Long()\n",
      "      %595 : Float(512, 512, 3, 3)\n",
      "      %596 : Float(512)\n",
      "      %597 : Float(512)\n",
      "      %598 : Float(512)\n",
      "      %599 : Float(512)\n",
      "      %600 : Long()\n",
      "      %601 : Float(2048, 512, 1, 1)\n",
      "      %602 : Float(2048)\n",
      "      %603 : Float(2048)\n",
      "      %604 : Float(2048)\n",
      "      %605 : Float(2048)\n",
      "      %606 : Long()\n",
      "      %607 : Float(512, 2048, 1, 1)\n",
      "      %608 : Float(512)\n",
      "      %609 : Float(512)\n",
      "      %610 : Float(512)\n",
      "      %611 : Float(512)\n",
      "      %612 : Long()\n",
      "      %613 : Float(512, 512, 3, 3)\n",
      "      %614 : Float(512)\n",
      "      %615 : Float(512)\n",
      "      %616 : Float(512)\n",
      "      %617 : Float(512)\n",
      "      %618 : Long()\n",
      "      %619 : Float(2048, 512, 1, 1)\n",
      "      %620 : Float(2048)\n",
      "      %621 : Float(2048)\n",
      "      %622 : Float(2048)\n",
      "      %623 : Float(2048)\n",
      "      %624 : Long()\n",
      "      %625 : Float(2048)\n",
      "      %626 : Float(2048)\n",
      "      %627 : Float(2048)\n",
      "      %628 : Float(2048)\n",
      "      %629 : Long()\n",
      "      %weight.1 : Float(4096, 2048, 3, 3)\n",
      "      %631 : Float(4096)\n",
      "      %632 : Float(18432)\n",
      "      %633 : Float(4096)\n",
      "      %634 : Float(4096)\n",
      "      %635 : Float(4096)\n",
      "      %636 : Float(4096)\n",
      "      %637 : Long()\n",
      "      %weight.2 : Float(2048, 4096, 3, 3)\n",
      "      %639 : Float(2048)\n",
      "      %640 : Float(36864)\n",
      "      %641 : Float(2048)\n",
      "      %642 : Float(2048)\n",
      "      %643 : Float(2048)\n",
      "      %644 : Float(2048)\n",
      "      %645 : Long()\n",
      "      %weight.3 : Float(2048, 2048, 1, 1)\n",
      "      %647 : Float(2048)\n",
      "      %648 : Float(2048)\n",
      "      %649 : Float(2048)\n",
      "      %650 : Float(2048)\n",
      "      %651 : Float(2048)\n",
      "      %652 : Float(2048)\n",
      "      %653 : Long()\n",
      "      %654 : Float(1024)\n",
      "      %655 : Float(1024)\n",
      "      %656 : Float(1024)\n",
      "      %657 : Float(1024)\n",
      "      %658 : Long()\n",
      "      %weight.4 : Float(512, 1536, 3, 3)\n",
      "      %660 : Float(512)\n",
      "      %661 : Float(13824)\n",
      "      %662 : Float(512)\n",
      "      %663 : Float(512)\n",
      "      %664 : Float(512)\n",
      "      %665 : Float(512)\n",
      "      %666 : Long()\n",
      "      %weight.5 : Float(2048, 512, 1, 1)\n",
      "      %668 : Float(2048)\n",
      "      %669 : Float(512)\n",
      "      %670 : Float(2048)\n",
      "      %671 : Float(2048)\n",
      "      %672 : Float(2048)\n",
      "      %673 : Float(2048)\n",
      "      %674 : Long()\n",
      "      %675 : Float(512)\n",
      "      %676 : Float(512)\n",
      "      %677 : Float(512)\n",
      "      %678 : Float(512)\n",
      "      %679 : Long()\n",
      "      %weight.6 : Float(512, 1024, 3, 3)\n",
      "      %681 : Float(512)\n",
      "      %682 : Float(9216)\n",
      "      %683 : Float(512)\n",
      "      %684 : Float(512)\n",
      "      %685 : Float(512)\n",
      "      %686 : Float(512)\n",
      "      %687 : Long()\n",
      "      %688 : Float(1)\n",
      "      %weight.7 : Float(64, 512, 1)\n",
      "      %690 : Float(64)\n",
      "      %691 : Float(512)\n",
      "      %weight.8 : Float(64, 512, 1)\n",
      "      %693 : Float(64)\n",
      "      %694 : Float(512)\n",
      "      %weight.9 : Float(512, 512, 1)\n",
      "      %696 : Float(512)\n",
      "      %697 : Float(512)\n",
      "      %weight.10 : Float(2048, 512, 1, 1)\n",
      "      %699 : Float(2048)\n",
      "      %700 : Float(512)\n",
      "      %701 : Float(2048)\n",
      "      %702 : Float(2048)\n",
      "      %703 : Float(2048)\n",
      "      %704 : Float(2048)\n",
      "      %705 : Long()\n",
      "      %706 : Float(256)\n",
      "      %707 : Float(256)\n",
      "      %708 : Float(256)\n",
      "      %709 : Float(256)\n",
      "      %710 : Long()\n",
      "      %weight.11 : Float(512, 768, 3, 3)\n",
      "      %712 : Float(512)\n",
      "      %713 : Float(6912)\n",
      "      %714 : Float(512)\n",
      "      %715 : Float(512)\n",
      "      %716 : Float(512)\n",
      "      %717 : Float(512)\n",
      "      %718 : Long()\n",
      "      %weight.12 : Float(1024, 512, 1, 1)\n",
      "      %720 : Float(1024)\n",
      "      %721 : Float(512)\n",
      "      %722 : Float(1024)\n",
      "      %723 : Float(1024)\n",
      "      %724 : Float(1024)\n",
      "      %725 : Float(1024)\n",
      "      %726 : Long()\n",
      "      %727 : Float(64)\n",
      "      %728 : Float(64)\n",
      "      %729 : Float(64)\n",
      "      %730 : Float(64)\n",
      "      %731 : Long()\n",
      "      %weight.13 : Float(256, 320, 3, 3)\n",
      "      %733 : Float(256)\n",
      "      %734 : Float(2880)\n",
      "      %735 : Float(256)\n",
      "      %736 : Float(256)\n",
      "      %737 : Float(256)\n",
      "      %738 : Float(256)\n",
      "      %739 : Long()\n",
      "      %740 : Float(1024)\n",
      "      %741 : Float(1024, 1, 1, 1)\n",
      "      %742 : Float(1024, 256, 1, 1)\n",
      "      %743 : Float(259)\n",
      "      %weight.14 : Float(259, 259, 3, 3)\n",
      "      %745 : Float(259)\n",
      "      %746 : Float(2331)\n",
      "      %747 : Float(259)\n",
      "      %weight.15 : Float(259, 259, 3, 3)\n",
      "      %749 : Float(259)\n",
      "      %750 : Float(2331)\n",
      "      %751 : Float(3)\n",
      "      %weight : Float(3, 259, 1, 1)\n",
      "      %753 : Float(3)\n",
      "      %754 : Float(259)) {\n",
      "  %755 : Float(1, 64, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[7, 7], pads=[3, 3, 3, 3], strides=[2, 2]](%0, %1), scope: DynamicUnetWide/Sequential/Conv2d[0]\n",
      "  %756 : Float(1, 64, 32, 32) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%755, %2, %3, %4, %5), scope: DynamicUnetWide/Sequential/BatchNorm2d[1]\n",
      "  %757 : Float(1, 64, 32, 32) = onnx::Relu(%756), scope: DynamicUnetWide/Sequential/ReLU[2]\n",
      "  %758 : Float(1, 64, 16, 16) = onnx::MaxPool[kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%757), scope: DynamicUnetWide/Sequential/MaxPool2d[3]\n",
      "  %759 : Float(1, 64, 16, 16) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%758, %7), scope: DynamicUnetWide/Sequential/Sequential[4]/Bottleneck[0]/Conv2d[conv1]\n",
      "  %760 : Float(1, 64, 16, 16) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%759, %8, %9, %10, %11), scope: DynamicUnetWide/Sequential/Sequential[4]/Bottleneck[0]/BatchNorm2d[bn1]\n",
      "  %761 : Float(1, 64, 16, 16) = onnx::Relu(%760), scope: DynamicUnetWide/Sequential/Sequential[4]/Bottleneck[0]/ReLU[relu]\n",
      "  %762 : Float(1, 64, 16, 16) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%761, %13), scope: DynamicUnetWide/Sequential/Sequential[4]/Bottleneck[0]/Conv2d[conv2]\n",
      "  %763 : Float(1, 64, 16, 16) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%762, %14, %15, %16, %17), scope: DynamicUnetWide/Sequential/Sequential[4]/Bottleneck[0]/BatchNorm2d[bn2]\n",
      "  %764 : Float(1, 64, 16, 16) = onnx::Relu(%763), scope: DynamicUnetWide/Sequential/Sequential[4]/Bottleneck[0]/ReLU[relu]\n",
      "  %765 : Float(1, 256, 16, 16) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%764, %19), scope: DynamicUnetWide/Sequential/Sequential[4]/Bottleneck[0]/Conv2d[conv3]\n",
      "  %766 : Float(1, 256, 16, 16) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%765, %20, %21, %22, %23), scope: DynamicUnetWide/Sequential/Sequential[4]/Bottleneck[0]/BatchNorm2d[bn3]\n",
      "  %767 : Float(1, 256, 16, 16) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%758, %25), scope: DynamicUnetWide/Sequential/Sequential[4]/Bottleneck[0]/Sequential[downsample]/Conv2d[0]\n",
      "  %768 : Float(1, 256, 16, 16) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%767, %26, %27, %28, %29), scope: DynamicUnetWide/Sequential/Sequential[4]/Bottleneck[0]/Sequential[downsample]/BatchNorm2d[1]\n",
      "  %769 : Float(1, 256, 16, 16) = onnx::Add(%766, %768), scope: DynamicUnetWide/Sequential/Sequential[4]/Bottleneck[0]\n",
      "  %770 : Float(1, 256, 16, 16) = onnx::Relu(%769), scope: DynamicUnetWide/Sequential/Sequential[4]/Bottleneck[0]/ReLU[relu]\n",
      "  %771 : Float(1, 64, 16, 16) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%770, %31), scope: DynamicUnetWide/Sequential/Sequential[4]/Bottleneck[1]/Conv2d[conv1]\n",
      "  %772 : Float(1, 64, 16, 16) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%771, %32, %33, %34, %35), scope: DynamicUnetWide/Sequential/Sequential[4]/Bottleneck[1]/BatchNorm2d[bn1]\n",
      "  %773 : Float(1, 64, 16, 16) = onnx::Relu(%772), scope: DynamicUnetWide/Sequential/Sequential[4]/Bottleneck[1]/ReLU[relu]\n",
      "  %774 : Float(1, 64, 16, 16) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%773, %37), scope: DynamicUnetWide/Sequential/Sequential[4]/Bottleneck[1]/Conv2d[conv2]\n",
      "  %775 : Float(1, 64, 16, 16) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%774, %38, %39, %40, %41), scope: DynamicUnetWide/Sequential/Sequential[4]/Bottleneck[1]/BatchNorm2d[bn2]\n",
      "  %776 : Float(1, 64, 16, 16) = onnx::Relu(%775), scope: DynamicUnetWide/Sequential/Sequential[4]/Bottleneck[1]/ReLU[relu]\n",
      "  %777 : Float(1, 256, 16, 16) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%776, %43), scope: DynamicUnetWide/Sequential/Sequential[4]/Bottleneck[1]/Conv2d[conv3]\n",
      "  %778 : Float(1, 256, 16, 16) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%777, %44, %45, %46, %47), scope: DynamicUnetWide/Sequential/Sequential[4]/Bottleneck[1]/BatchNorm2d[bn3]\n",
      "  %779 : Float(1, 256, 16, 16) = onnx::Add(%778, %770), scope: DynamicUnetWide/Sequential/Sequential[4]/Bottleneck[1]\n",
      "  %780 : Float(1, 256, 16, 16) = onnx::Relu(%779), scope: DynamicUnetWide/Sequential/Sequential[4]/Bottleneck[1]/ReLU[relu]\n",
      "  %781 : Float(1, 64, 16, 16) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%780, %49), scope: DynamicUnetWide/Sequential/Sequential[4]/Bottleneck[2]/Conv2d[conv1]\n",
      "  %782 : Float(1, 64, 16, 16) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%781, %50, %51, %52, %53), scope: DynamicUnetWide/Sequential/Sequential[4]/Bottleneck[2]/BatchNorm2d[bn1]\n",
      "  %783 : Float(1, 64, 16, 16) = onnx::Relu(%782), scope: DynamicUnetWide/Sequential/Sequential[4]/Bottleneck[2]/ReLU[relu]\n",
      "  %784 : Float(1, 64, 16, 16) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%783, %55), scope: DynamicUnetWide/Sequential/Sequential[4]/Bottleneck[2]/Conv2d[conv2]\n",
      "  %785 : Float(1, 64, 16, 16) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%784, %56, %57, %58, %59), scope: DynamicUnetWide/Sequential/Sequential[4]/Bottleneck[2]/BatchNorm2d[bn2]\n",
      "  %786 : Float(1, 64, 16, 16) = onnx::Relu(%785), scope: DynamicUnetWide/Sequential/Sequential[4]/Bottleneck[2]/ReLU[relu]\n",
      "  %787 : Float(1, 256, 16, 16) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%786, %61), scope: DynamicUnetWide/Sequential/Sequential[4]/Bottleneck[2]/Conv2d[conv3]\n",
      "  %788 : Float(1, 256, 16, 16) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%787, %62, %63, %64, %65), scope: DynamicUnetWide/Sequential/Sequential[4]/Bottleneck[2]/BatchNorm2d[bn3]\n",
      "  %789 : Float(1, 256, 16, 16) = onnx::Add(%788, %780), scope: DynamicUnetWide/Sequential/Sequential[4]/Bottleneck[2]\n",
      "  %790 : Float(1, 256, 16, 16) = onnx::Relu(%789), scope: DynamicUnetWide/Sequential/Sequential[4]/Bottleneck[2]/ReLU[relu]\n",
      "  %791 : Float(1, 128, 16, 16) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%790, %67), scope: DynamicUnetWide/Sequential/Sequential[5]/Bottleneck[0]/Conv2d[conv1]\n",
      "  %792 : Float(1, 128, 16, 16) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%791, %68, %69, %70, %71), scope: DynamicUnetWide/Sequential/Sequential[5]/Bottleneck[0]/BatchNorm2d[bn1]\n",
      "  %793 : Float(1, 128, 16, 16) = onnx::Relu(%792), scope: DynamicUnetWide/Sequential/Sequential[5]/Bottleneck[0]/ReLU[relu]\n",
      "  %794 : Float(1, 128, 8, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%793, %73), scope: DynamicUnetWide/Sequential/Sequential[5]/Bottleneck[0]/Conv2d[conv2]\n",
      "  %795 : Float(1, 128, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%794, %74, %75, %76, %77), scope: DynamicUnetWide/Sequential/Sequential[5]/Bottleneck[0]/BatchNorm2d[bn2]\n",
      "  %796 : Float(1, 128, 8, 8) = onnx::Relu(%795), scope: DynamicUnetWide/Sequential/Sequential[5]/Bottleneck[0]/ReLU[relu]\n",
      "  %797 : Float(1, 512, 8, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%796, %79), scope: DynamicUnetWide/Sequential/Sequential[5]/Bottleneck[0]/Conv2d[conv3]\n",
      "  %798 : Float(1, 512, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%797, %80, %81, %82, %83), scope: DynamicUnetWide/Sequential/Sequential[5]/Bottleneck[0]/BatchNorm2d[bn3]\n",
      "  %799 : Float(1, 512, 8, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[2, 2]](%790, %85), scope: DynamicUnetWide/Sequential/Sequential[5]/Bottleneck[0]/Sequential[downsample]/Conv2d[0]\n",
      "  %800 : Float(1, 512, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%799, %86, %87, %88, %89), scope: DynamicUnetWide/Sequential/Sequential[5]/Bottleneck[0]/Sequential[downsample]/BatchNorm2d[1]\n",
      "  %801 : Float(1, 512, 8, 8) = onnx::Add(%798, %800), scope: DynamicUnetWide/Sequential/Sequential[5]/Bottleneck[0]\n",
      "  %802 : Float(1, 512, 8, 8) = onnx::Relu(%801), scope: DynamicUnetWide/Sequential/Sequential[5]/Bottleneck[0]/ReLU[relu]\n",
      "  %803 : Float(1, 128, 8, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%802, %91), scope: DynamicUnetWide/Sequential/Sequential[5]/Bottleneck[1]/Conv2d[conv1]\n",
      "  %804 : Float(1, 128, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%803, %92, %93, %94, %95), scope: DynamicUnetWide/Sequential/Sequential[5]/Bottleneck[1]/BatchNorm2d[bn1]\n",
      "  %805 : Float(1, 128, 8, 8) = onnx::Relu(%804), scope: DynamicUnetWide/Sequential/Sequential[5]/Bottleneck[1]/ReLU[relu]\n",
      "  %806 : Float(1, 128, 8, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%805, %97), scope: DynamicUnetWide/Sequential/Sequential[5]/Bottleneck[1]/Conv2d[conv2]\n",
      "  %807 : Float(1, 128, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%806, %98, %99, %100, %101), scope: DynamicUnetWide/Sequential/Sequential[5]/Bottleneck[1]/BatchNorm2d[bn2]\n",
      "  %808 : Float(1, 128, 8, 8) = onnx::Relu(%807), scope: DynamicUnetWide/Sequential/Sequential[5]/Bottleneck[1]/ReLU[relu]\n",
      "  %809 : Float(1, 512, 8, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%808, %103), scope: DynamicUnetWide/Sequential/Sequential[5]/Bottleneck[1]/Conv2d[conv3]\n",
      "  %810 : Float(1, 512, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%809, %104, %105, %106, %107), scope: DynamicUnetWide/Sequential/Sequential[5]/Bottleneck[1]/BatchNorm2d[bn3]\n",
      "  %811 : Float(1, 512, 8, 8) = onnx::Add(%810, %802), scope: DynamicUnetWide/Sequential/Sequential[5]/Bottleneck[1]\n",
      "  %812 : Float(1, 512, 8, 8) = onnx::Relu(%811), scope: DynamicUnetWide/Sequential/Sequential[5]/Bottleneck[1]/ReLU[relu]\n",
      "  %813 : Float(1, 128, 8, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%812, %109), scope: DynamicUnetWide/Sequential/Sequential[5]/Bottleneck[2]/Conv2d[conv1]\n",
      "  %814 : Float(1, 128, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%813, %110, %111, %112, %113), scope: DynamicUnetWide/Sequential/Sequential[5]/Bottleneck[2]/BatchNorm2d[bn1]\n",
      "  %815 : Float(1, 128, 8, 8) = onnx::Relu(%814), scope: DynamicUnetWide/Sequential/Sequential[5]/Bottleneck[2]/ReLU[relu]\n",
      "  %816 : Float(1, 128, 8, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%815, %115), scope: DynamicUnetWide/Sequential/Sequential[5]/Bottleneck[2]/Conv2d[conv2]\n",
      "  %817 : Float(1, 128, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%816, %116, %117, %118, %119), scope: DynamicUnetWide/Sequential/Sequential[5]/Bottleneck[2]/BatchNorm2d[bn2]\n",
      "  %818 : Float(1, 128, 8, 8) = onnx::Relu(%817), scope: DynamicUnetWide/Sequential/Sequential[5]/Bottleneck[2]/ReLU[relu]\n",
      "  %819 : Float(1, 512, 8, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%818, %121), scope: DynamicUnetWide/Sequential/Sequential[5]/Bottleneck[2]/Conv2d[conv3]\n",
      "  %820 : Float(1, 512, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%819, %122, %123, %124, %125), scope: DynamicUnetWide/Sequential/Sequential[5]/Bottleneck[2]/BatchNorm2d[bn3]\n",
      "  %821 : Float(1, 512, 8, 8) = onnx::Add(%820, %812), scope: DynamicUnetWide/Sequential/Sequential[5]/Bottleneck[2]\n",
      "  %822 : Float(1, 512, 8, 8) = onnx::Relu(%821), scope: DynamicUnetWide/Sequential/Sequential[5]/Bottleneck[2]/ReLU[relu]\n",
      "  %823 : Float(1, 128, 8, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%822, %127), scope: DynamicUnetWide/Sequential/Sequential[5]/Bottleneck[3]/Conv2d[conv1]\n",
      "  %824 : Float(1, 128, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%823, %128, %129, %130, %131), scope: DynamicUnetWide/Sequential/Sequential[5]/Bottleneck[3]/BatchNorm2d[bn1]\n",
      "  %825 : Float(1, 128, 8, 8) = onnx::Relu(%824), scope: DynamicUnetWide/Sequential/Sequential[5]/Bottleneck[3]/ReLU[relu]\n",
      "  %826 : Float(1, 128, 8, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%825, %133), scope: DynamicUnetWide/Sequential/Sequential[5]/Bottleneck[3]/Conv2d[conv2]\n",
      "  %827 : Float(1, 128, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%826, %134, %135, %136, %137), scope: DynamicUnetWide/Sequential/Sequential[5]/Bottleneck[3]/BatchNorm2d[bn2]\n",
      "  %828 : Float(1, 128, 8, 8) = onnx::Relu(%827), scope: DynamicUnetWide/Sequential/Sequential[5]/Bottleneck[3]/ReLU[relu]\n",
      "  %829 : Float(1, 512, 8, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%828, %139), scope: DynamicUnetWide/Sequential/Sequential[5]/Bottleneck[3]/Conv2d[conv3]\n",
      "  %830 : Float(1, 512, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%829, %140, %141, %142, %143), scope: DynamicUnetWide/Sequential/Sequential[5]/Bottleneck[3]/BatchNorm2d[bn3]\n",
      "  %831 : Float(1, 512, 8, 8) = onnx::Add(%830, %822), scope: DynamicUnetWide/Sequential/Sequential[5]/Bottleneck[3]\n",
      "  %832 : Float(1, 512, 8, 8) = onnx::Relu(%831), scope: DynamicUnetWide/Sequential/Sequential[5]/Bottleneck[3]/ReLU[relu]\n",
      "  %833 : Float(1, 256, 8, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%832, %145), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[0]/Conv2d[conv1]\n",
      "  %834 : Float(1, 256, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%833, %146, %147, %148, %149), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[0]/BatchNorm2d[bn1]\n",
      "  %835 : Float(1, 256, 8, 8) = onnx::Relu(%834), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[0]/ReLU[relu]\n",
      "  %836 : Float(1, 256, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%835, %151), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[0]/Conv2d[conv2]\n",
      "  %837 : Float(1, 256, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%836, %152, %153, %154, %155), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[0]/BatchNorm2d[bn2]\n",
      "  %838 : Float(1, 256, 4, 4) = onnx::Relu(%837), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[0]/ReLU[relu]\n",
      "  %839 : Float(1, 1024, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%838, %157), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[0]/Conv2d[conv3]\n",
      "  %840 : Float(1, 1024, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%839, %158, %159, %160, %161), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[0]/BatchNorm2d[bn3]\n",
      "  %841 : Float(1, 1024, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[2, 2]](%832, %163), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[0]/Sequential[downsample]/Conv2d[0]\n",
      "  %842 : Float(1, 1024, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%841, %164, %165, %166, %167), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[0]/Sequential[downsample]/BatchNorm2d[1]\n",
      "  %843 : Float(1, 1024, 4, 4) = onnx::Add(%840, %842), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[0]\n",
      "  %844 : Float(1, 1024, 4, 4) = onnx::Relu(%843), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[0]/ReLU[relu]\n",
      "  %845 : Float(1, 256, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%844, %169), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[1]/Conv2d[conv1]\n",
      "  %846 : Float(1, 256, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%845, %170, %171, %172, %173), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[1]/BatchNorm2d[bn1]\n",
      "  %847 : Float(1, 256, 4, 4) = onnx::Relu(%846), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[1]/ReLU[relu]\n",
      "  %848 : Float(1, 256, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%847, %175), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[1]/Conv2d[conv2]\n",
      "  %849 : Float(1, 256, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%848, %176, %177, %178, %179), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[1]/BatchNorm2d[bn2]\n",
      "  %850 : Float(1, 256, 4, 4) = onnx::Relu(%849), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[1]/ReLU[relu]\n",
      "  %851 : Float(1, 1024, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%850, %181), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[1]/Conv2d[conv3]\n",
      "  %852 : Float(1, 1024, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%851, %182, %183, %184, %185), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[1]/BatchNorm2d[bn3]\n",
      "  %853 : Float(1, 1024, 4, 4) = onnx::Add(%852, %844), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[1]\n",
      "  %854 : Float(1, 1024, 4, 4) = onnx::Relu(%853), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[1]/ReLU[relu]\n",
      "  %855 : Float(1, 256, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%854, %187), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[2]/Conv2d[conv1]\n",
      "  %856 : Float(1, 256, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%855, %188, %189, %190, %191), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[2]/BatchNorm2d[bn1]\n",
      "  %857 : Float(1, 256, 4, 4) = onnx::Relu(%856), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[2]/ReLU[relu]\n",
      "  %858 : Float(1, 256, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%857, %193), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[2]/Conv2d[conv2]\n",
      "  %859 : Float(1, 256, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%858, %194, %195, %196, %197), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[2]/BatchNorm2d[bn2]\n",
      "  %860 : Float(1, 256, 4, 4) = onnx::Relu(%859), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[2]/ReLU[relu]\n",
      "  %861 : Float(1, 1024, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%860, %199), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[2]/Conv2d[conv3]\n",
      "  %862 : Float(1, 1024, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%861, %200, %201, %202, %203), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[2]/BatchNorm2d[bn3]\n",
      "  %863 : Float(1, 1024, 4, 4) = onnx::Add(%862, %854), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[2]\n",
      "  %864 : Float(1, 1024, 4, 4) = onnx::Relu(%863), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[2]/ReLU[relu]\n",
      "  %865 : Float(1, 256, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%864, %205), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[3]/Conv2d[conv1]\n",
      "  %866 : Float(1, 256, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%865, %206, %207, %208, %209), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[3]/BatchNorm2d[bn1]\n",
      "  %867 : Float(1, 256, 4, 4) = onnx::Relu(%866), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[3]/ReLU[relu]\n",
      "  %868 : Float(1, 256, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%867, %211), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[3]/Conv2d[conv2]\n",
      "  %869 : Float(1, 256, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%868, %212, %213, %214, %215), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[3]/BatchNorm2d[bn2]\n",
      "  %870 : Float(1, 256, 4, 4) = onnx::Relu(%869), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[3]/ReLU[relu]\n",
      "  %871 : Float(1, 1024, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%870, %217), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[3]/Conv2d[conv3]\n",
      "  %872 : Float(1, 1024, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%871, %218, %219, %220, %221), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[3]/BatchNorm2d[bn3]\n",
      "  %873 : Float(1, 1024, 4, 4) = onnx::Add(%872, %864), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[3]\n",
      "  %874 : Float(1, 1024, 4, 4) = onnx::Relu(%873), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[3]/ReLU[relu]\n",
      "  %875 : Float(1, 256, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%874, %223), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[4]/Conv2d[conv1]\n",
      "  %876 : Float(1, 256, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%875, %224, %225, %226, %227), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[4]/BatchNorm2d[bn1]\n",
      "  %877 : Float(1, 256, 4, 4) = onnx::Relu(%876), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[4]/ReLU[relu]\n",
      "  %878 : Float(1, 256, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%877, %229), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[4]/Conv2d[conv2]\n",
      "  %879 : Float(1, 256, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%878, %230, %231, %232, %233), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[4]/BatchNorm2d[bn2]\n",
      "  %880 : Float(1, 256, 4, 4) = onnx::Relu(%879), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[4]/ReLU[relu]\n",
      "  %881 : Float(1, 1024, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%880, %235), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[4]/Conv2d[conv3]\n",
      "  %882 : Float(1, 1024, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%881, %236, %237, %238, %239), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[4]/BatchNorm2d[bn3]\n",
      "  %883 : Float(1, 1024, 4, 4) = onnx::Add(%882, %874), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[4]\n",
      "  %884 : Float(1, 1024, 4, 4) = onnx::Relu(%883), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[4]/ReLU[relu]\n",
      "  %885 : Float(1, 256, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%884, %241), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[5]/Conv2d[conv1]\n",
      "  %886 : Float(1, 256, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%885, %242, %243, %244, %245), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[5]/BatchNorm2d[bn1]\n",
      "  %887 : Float(1, 256, 4, 4) = onnx::Relu(%886), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[5]/ReLU[relu]\n",
      "  %888 : Float(1, 256, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%887, %247), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[5]/Conv2d[conv2]\n",
      "  %889 : Float(1, 256, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%888, %248, %249, %250, %251), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[5]/BatchNorm2d[bn2]\n",
      "  %890 : Float(1, 256, 4, 4) = onnx::Relu(%889), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[5]/ReLU[relu]\n",
      "  %891 : Float(1, 1024, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%890, %253), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[5]/Conv2d[conv3]\n",
      "  %892 : Float(1, 1024, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%891, %254, %255, %256, %257), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[5]/BatchNorm2d[bn3]\n",
      "  %893 : Float(1, 1024, 4, 4) = onnx::Add(%892, %884), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[5]\n",
      "  %894 : Float(1, 1024, 4, 4) = onnx::Relu(%893), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[5]/ReLU[relu]\n",
      "  %895 : Float(1, 256, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%894, %259), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[6]/Conv2d[conv1]\n",
      "  %896 : Float(1, 256, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%895, %260, %261, %262, %263), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[6]/BatchNorm2d[bn1]\n",
      "  %897 : Float(1, 256, 4, 4) = onnx::Relu(%896), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[6]/ReLU[relu]\n",
      "  %898 : Float(1, 256, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%897, %265), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[6]/Conv2d[conv2]\n",
      "  %899 : Float(1, 256, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%898, %266, %267, %268, %269), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[6]/BatchNorm2d[bn2]\n",
      "  %900 : Float(1, 256, 4, 4) = onnx::Relu(%899), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[6]/ReLU[relu]\n",
      "  %901 : Float(1, 1024, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%900, %271), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[6]/Conv2d[conv3]\n",
      "  %902 : Float(1, 1024, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%901, %272, %273, %274, %275), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[6]/BatchNorm2d[bn3]\n",
      "  %903 : Float(1, 1024, 4, 4) = onnx::Add(%902, %894), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[6]\n",
      "  %904 : Float(1, 1024, 4, 4) = onnx::Relu(%903), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[6]/ReLU[relu]\n",
      "  %905 : Float(1, 256, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%904, %277), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[7]/Conv2d[conv1]\n",
      "  %906 : Float(1, 256, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%905, %278, %279, %280, %281), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[7]/BatchNorm2d[bn1]\n",
      "  %907 : Float(1, 256, 4, 4) = onnx::Relu(%906), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[7]/ReLU[relu]\n",
      "  %908 : Float(1, 256, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%907, %283), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[7]/Conv2d[conv2]\n",
      "  %909 : Float(1, 256, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%908, %284, %285, %286, %287), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[7]/BatchNorm2d[bn2]\n",
      "  %910 : Float(1, 256, 4, 4) = onnx::Relu(%909), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[7]/ReLU[relu]\n",
      "  %911 : Float(1, 1024, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%910, %289), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[7]/Conv2d[conv3]\n",
      "  %912 : Float(1, 1024, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%911, %290, %291, %292, %293), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[7]/BatchNorm2d[bn3]\n",
      "  %913 : Float(1, 1024, 4, 4) = onnx::Add(%912, %904), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[7]\n",
      "  %914 : Float(1, 1024, 4, 4) = onnx::Relu(%913), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[7]/ReLU[relu]\n",
      "  %915 : Float(1, 256, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%914, %295), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[8]/Conv2d[conv1]\n",
      "  %916 : Float(1, 256, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%915, %296, %297, %298, %299), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[8]/BatchNorm2d[bn1]\n",
      "  %917 : Float(1, 256, 4, 4) = onnx::Relu(%916), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[8]/ReLU[relu]\n",
      "  %918 : Float(1, 256, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%917, %301), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[8]/Conv2d[conv2]\n",
      "  %919 : Float(1, 256, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%918, %302, %303, %304, %305), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[8]/BatchNorm2d[bn2]\n",
      "  %920 : Float(1, 256, 4, 4) = onnx::Relu(%919), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[8]/ReLU[relu]\n",
      "  %921 : Float(1, 1024, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%920, %307), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[8]/Conv2d[conv3]\n",
      "  %922 : Float(1, 1024, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%921, %308, %309, %310, %311), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[8]/BatchNorm2d[bn3]\n",
      "  %923 : Float(1, 1024, 4, 4) = onnx::Add(%922, %914), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[8]\n",
      "  %924 : Float(1, 1024, 4, 4) = onnx::Relu(%923), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[8]/ReLU[relu]\n",
      "  %925 : Float(1, 256, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%924, %313), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[9]/Conv2d[conv1]\n",
      "  %926 : Float(1, 256, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%925, %314, %315, %316, %317), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[9]/BatchNorm2d[bn1]\n",
      "  %927 : Float(1, 256, 4, 4) = onnx::Relu(%926), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[9]/ReLU[relu]\n",
      "  %928 : Float(1, 256, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%927, %319), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[9]/Conv2d[conv2]\n",
      "  %929 : Float(1, 256, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%928, %320, %321, %322, %323), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[9]/BatchNorm2d[bn2]\n",
      "  %930 : Float(1, 256, 4, 4) = onnx::Relu(%929), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[9]/ReLU[relu]\n",
      "  %931 : Float(1, 1024, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%930, %325), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[9]/Conv2d[conv3]\n",
      "  %932 : Float(1, 1024, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%931, %326, %327, %328, %329), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[9]/BatchNorm2d[bn3]\n",
      "  %933 : Float(1, 1024, 4, 4) = onnx::Add(%932, %924), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[9]\n",
      "  %934 : Float(1, 1024, 4, 4) = onnx::Relu(%933), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[9]/ReLU[relu]\n",
      "  %935 : Float(1, 256, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%934, %331), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[10]/Conv2d[conv1]\n",
      "  %936 : Float(1, 256, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%935, %332, %333, %334, %335), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[10]/BatchNorm2d[bn1]\n",
      "  %937 : Float(1, 256, 4, 4) = onnx::Relu(%936), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[10]/ReLU[relu]\n",
      "  %938 : Float(1, 256, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%937, %337), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[10]/Conv2d[conv2]\n",
      "  %939 : Float(1, 256, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%938, %338, %339, %340, %341), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[10]/BatchNorm2d[bn2]\n",
      "  %940 : Float(1, 256, 4, 4) = onnx::Relu(%939), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[10]/ReLU[relu]\n",
      "  %941 : Float(1, 1024, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%940, %343), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[10]/Conv2d[conv3]\n",
      "  %942 : Float(1, 1024, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%941, %344, %345, %346, %347), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[10]/BatchNorm2d[bn3]\n",
      "  %943 : Float(1, 1024, 4, 4) = onnx::Add(%942, %934), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[10]\n",
      "  %944 : Float(1, 1024, 4, 4) = onnx::Relu(%943), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[10]/ReLU[relu]\n",
      "  %945 : Float(1, 256, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%944, %349), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[11]/Conv2d[conv1]\n",
      "  %946 : Float(1, 256, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%945, %350, %351, %352, %353), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[11]/BatchNorm2d[bn1]\n",
      "  %947 : Float(1, 256, 4, 4) = onnx::Relu(%946), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[11]/ReLU[relu]\n",
      "  %948 : Float(1, 256, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%947, %355), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[11]/Conv2d[conv2]\n",
      "  %949 : Float(1, 256, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%948, %356, %357, %358, %359), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[11]/BatchNorm2d[bn2]\n",
      "  %950 : Float(1, 256, 4, 4) = onnx::Relu(%949), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[11]/ReLU[relu]\n",
      "  %951 : Float(1, 1024, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%950, %361), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[11]/Conv2d[conv3]\n",
      "  %952 : Float(1, 1024, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%951, %362, %363, %364, %365), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[11]/BatchNorm2d[bn3]\n",
      "  %953 : Float(1, 1024, 4, 4) = onnx::Add(%952, %944), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[11]\n",
      "  %954 : Float(1, 1024, 4, 4) = onnx::Relu(%953), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[11]/ReLU[relu]\n",
      "  %955 : Float(1, 256, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%954, %367), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[12]/Conv2d[conv1]\n",
      "  %956 : Float(1, 256, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%955, %368, %369, %370, %371), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[12]/BatchNorm2d[bn1]\n",
      "  %957 : Float(1, 256, 4, 4) = onnx::Relu(%956), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[12]/ReLU[relu]\n",
      "  %958 : Float(1, 256, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%957, %373), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[12]/Conv2d[conv2]\n",
      "  %959 : Float(1, 256, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%958, %374, %375, %376, %377), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[12]/BatchNorm2d[bn2]\n",
      "  %960 : Float(1, 256, 4, 4) = onnx::Relu(%959), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[12]/ReLU[relu]\n",
      "  %961 : Float(1, 1024, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%960, %379), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[12]/Conv2d[conv3]\n",
      "  %962 : Float(1, 1024, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%961, %380, %381, %382, %383), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[12]/BatchNorm2d[bn3]\n",
      "  %963 : Float(1, 1024, 4, 4) = onnx::Add(%962, %954), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[12]\n",
      "  %964 : Float(1, 1024, 4, 4) = onnx::Relu(%963), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[12]/ReLU[relu]\n",
      "  %965 : Float(1, 256, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%964, %385), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[13]/Conv2d[conv1]\n",
      "  %966 : Float(1, 256, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%965, %386, %387, %388, %389), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[13]/BatchNorm2d[bn1]\n",
      "  %967 : Float(1, 256, 4, 4) = onnx::Relu(%966), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[13]/ReLU[relu]\n",
      "  %968 : Float(1, 256, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%967, %391), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[13]/Conv2d[conv2]\n",
      "  %969 : Float(1, 256, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%968, %392, %393, %394, %395), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[13]/BatchNorm2d[bn2]\n",
      "  %970 : Float(1, 256, 4, 4) = onnx::Relu(%969), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[13]/ReLU[relu]\n",
      "  %971 : Float(1, 1024, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%970, %397), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[13]/Conv2d[conv3]\n",
      "  %972 : Float(1, 1024, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%971, %398, %399, %400, %401), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[13]/BatchNorm2d[bn3]\n",
      "  %973 : Float(1, 1024, 4, 4) = onnx::Add(%972, %964), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[13]\n",
      "  %974 : Float(1, 1024, 4, 4) = onnx::Relu(%973), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[13]/ReLU[relu]\n",
      "  %975 : Float(1, 256, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%974, %403), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[14]/Conv2d[conv1]\n",
      "  %976 : Float(1, 256, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%975, %404, %405, %406, %407), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[14]/BatchNorm2d[bn1]\n",
      "  %977 : Float(1, 256, 4, 4) = onnx::Relu(%976), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[14]/ReLU[relu]\n",
      "  %978 : Float(1, 256, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%977, %409), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[14]/Conv2d[conv2]\n",
      "  %979 : Float(1, 256, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%978, %410, %411, %412, %413), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[14]/BatchNorm2d[bn2]\n",
      "  %980 : Float(1, 256, 4, 4) = onnx::Relu(%979), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[14]/ReLU[relu]\n",
      "  %981 : Float(1, 1024, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%980, %415), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[14]/Conv2d[conv3]\n",
      "  %982 : Float(1, 1024, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%981, %416, %417, %418, %419), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[14]/BatchNorm2d[bn3]\n",
      "  %983 : Float(1, 1024, 4, 4) = onnx::Add(%982, %974), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[14]\n",
      "  %984 : Float(1, 1024, 4, 4) = onnx::Relu(%983), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[14]/ReLU[relu]\n",
      "  %985 : Float(1, 256, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%984, %421), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[15]/Conv2d[conv1]\n",
      "  %986 : Float(1, 256, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%985, %422, %423, %424, %425), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[15]/BatchNorm2d[bn1]\n",
      "  %987 : Float(1, 256, 4, 4) = onnx::Relu(%986), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[15]/ReLU[relu]\n",
      "  %988 : Float(1, 256, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%987, %427), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[15]/Conv2d[conv2]\n",
      "  %989 : Float(1, 256, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%988, %428, %429, %430, %431), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[15]/BatchNorm2d[bn2]\n",
      "  %990 : Float(1, 256, 4, 4) = onnx::Relu(%989), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[15]/ReLU[relu]\n",
      "  %991 : Float(1, 1024, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%990, %433), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[15]/Conv2d[conv3]\n",
      "  %992 : Float(1, 1024, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%991, %434, %435, %436, %437), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[15]/BatchNorm2d[bn3]\n",
      "  %993 : Float(1, 1024, 4, 4) = onnx::Add(%992, %984), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[15]\n",
      "  %994 : Float(1, 1024, 4, 4) = onnx::Relu(%993), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[15]/ReLU[relu]\n",
      "  %995 : Float(1, 256, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%994, %439), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[16]/Conv2d[conv1]\n",
      "  %996 : Float(1, 256, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%995, %440, %441, %442, %443), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[16]/BatchNorm2d[bn1]\n",
      "  %997 : Float(1, 256, 4, 4) = onnx::Relu(%996), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[16]/ReLU[relu]\n",
      "  %998 : Float(1, 256, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%997, %445), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[16]/Conv2d[conv2]\n",
      "  %999 : Float(1, 256, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%998, %446, %447, %448, %449), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[16]/BatchNorm2d[bn2]\n",
      "  %1000 : Float(1, 256, 4, 4) = onnx::Relu(%999), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[16]/ReLU[relu]\n",
      "  %1001 : Float(1, 1024, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1000, %451), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[16]/Conv2d[conv3]\n",
      "  %1002 : Float(1, 1024, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%1001, %452, %453, %454, %455), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[16]/BatchNorm2d[bn3]\n",
      "  %1003 : Float(1, 1024, 4, 4) = onnx::Add(%1002, %994), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[16]\n",
      "  %1004 : Float(1, 1024, 4, 4) = onnx::Relu(%1003), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[16]/ReLU[relu]\n",
      "  %1005 : Float(1, 256, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1004, %457), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[17]/Conv2d[conv1]\n",
      "  %1006 : Float(1, 256, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%1005, %458, %459, %460, %461), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[17]/BatchNorm2d[bn1]\n",
      "  %1007 : Float(1, 256, 4, 4) = onnx::Relu(%1006), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[17]/ReLU[relu]\n",
      "  %1008 : Float(1, 256, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1007, %463), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[17]/Conv2d[conv2]\n",
      "  %1009 : Float(1, 256, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%1008, %464, %465, %466, %467), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[17]/BatchNorm2d[bn2]\n",
      "  %1010 : Float(1, 256, 4, 4) = onnx::Relu(%1009), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[17]/ReLU[relu]\n",
      "  %1011 : Float(1, 1024, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1010, %469), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[17]/Conv2d[conv3]\n",
      "  %1012 : Float(1, 1024, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%1011, %470, %471, %472, %473), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[17]/BatchNorm2d[bn3]\n",
      "  %1013 : Float(1, 1024, 4, 4) = onnx::Add(%1012, %1004), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[17]\n",
      "  %1014 : Float(1, 1024, 4, 4) = onnx::Relu(%1013), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[17]/ReLU[relu]\n",
      "  %1015 : Float(1, 256, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1014, %475), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[18]/Conv2d[conv1]\n",
      "  %1016 : Float(1, 256, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%1015, %476, %477, %478, %479), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[18]/BatchNorm2d[bn1]\n",
      "  %1017 : Float(1, 256, 4, 4) = onnx::Relu(%1016), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[18]/ReLU[relu]\n",
      "  %1018 : Float(1, 256, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1017, %481), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[18]/Conv2d[conv2]\n",
      "  %1019 : Float(1, 256, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%1018, %482, %483, %484, %485), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[18]/BatchNorm2d[bn2]\n",
      "  %1020 : Float(1, 256, 4, 4) = onnx::Relu(%1019), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[18]/ReLU[relu]\n",
      "  %1021 : Float(1, 1024, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1020, %487), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[18]/Conv2d[conv3]\n",
      "  %1022 : Float(1, 1024, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%1021, %488, %489, %490, %491), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[18]/BatchNorm2d[bn3]\n",
      "  %1023 : Float(1, 1024, 4, 4) = onnx::Add(%1022, %1014), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[18]\n",
      "  %1024 : Float(1, 1024, 4, 4) = onnx::Relu(%1023), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[18]/ReLU[relu]\n",
      "  %1025 : Float(1, 256, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1024, %493), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[19]/Conv2d[conv1]\n",
      "  %1026 : Float(1, 256, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%1025, %494, %495, %496, %497), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[19]/BatchNorm2d[bn1]\n",
      "  %1027 : Float(1, 256, 4, 4) = onnx::Relu(%1026), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[19]/ReLU[relu]\n",
      "  %1028 : Float(1, 256, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1027, %499), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[19]/Conv2d[conv2]\n",
      "  %1029 : Float(1, 256, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%1028, %500, %501, %502, %503), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[19]/BatchNorm2d[bn2]\n",
      "  %1030 : Float(1, 256, 4, 4) = onnx::Relu(%1029), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[19]/ReLU[relu]\n",
      "  %1031 : Float(1, 1024, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1030, %505), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[19]/Conv2d[conv3]\n",
      "  %1032 : Float(1, 1024, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%1031, %506, %507, %508, %509), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[19]/BatchNorm2d[bn3]\n",
      "  %1033 : Float(1, 1024, 4, 4) = onnx::Add(%1032, %1024), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[19]\n",
      "  %1034 : Float(1, 1024, 4, 4) = onnx::Relu(%1033), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[19]/ReLU[relu]\n",
      "  %1035 : Float(1, 256, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1034, %511), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[20]/Conv2d[conv1]\n",
      "  %1036 : Float(1, 256, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%1035, %512, %513, %514, %515), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[20]/BatchNorm2d[bn1]\n",
      "  %1037 : Float(1, 256, 4, 4) = onnx::Relu(%1036), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[20]/ReLU[relu]\n",
      "  %1038 : Float(1, 256, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1037, %517), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[20]/Conv2d[conv2]\n",
      "  %1039 : Float(1, 256, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%1038, %518, %519, %520, %521), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[20]/BatchNorm2d[bn2]\n",
      "  %1040 : Float(1, 256, 4, 4) = onnx::Relu(%1039), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[20]/ReLU[relu]\n",
      "  %1041 : Float(1, 1024, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1040, %523), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[20]/Conv2d[conv3]\n",
      "  %1042 : Float(1, 1024, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%1041, %524, %525, %526, %527), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[20]/BatchNorm2d[bn3]\n",
      "  %1043 : Float(1, 1024, 4, 4) = onnx::Add(%1042, %1034), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[20]\n",
      "  %1044 : Float(1, 1024, 4, 4) = onnx::Relu(%1043), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[20]/ReLU[relu]\n",
      "  %1045 : Float(1, 256, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1044, %529), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[21]/Conv2d[conv1]\n",
      "  %1046 : Float(1, 256, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%1045, %530, %531, %532, %533), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[21]/BatchNorm2d[bn1]\n",
      "  %1047 : Float(1, 256, 4, 4) = onnx::Relu(%1046), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[21]/ReLU[relu]\n",
      "  %1048 : Float(1, 256, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1047, %535), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[21]/Conv2d[conv2]\n",
      "  %1049 : Float(1, 256, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%1048, %536, %537, %538, %539), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[21]/BatchNorm2d[bn2]\n",
      "  %1050 : Float(1, 256, 4, 4) = onnx::Relu(%1049), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[21]/ReLU[relu]\n",
      "  %1051 : Float(1, 1024, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1050, %541), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[21]/Conv2d[conv3]\n",
      "  %1052 : Float(1, 1024, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%1051, %542, %543, %544, %545), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[21]/BatchNorm2d[bn3]\n",
      "  %1053 : Float(1, 1024, 4, 4) = onnx::Add(%1052, %1044), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[21]\n",
      "  %1054 : Float(1, 1024, 4, 4) = onnx::Relu(%1053), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[21]/ReLU[relu]\n",
      "  %1055 : Float(1, 256, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1054, %547), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[22]/Conv2d[conv1]\n",
      "  %1056 : Float(1, 256, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%1055, %548, %549, %550, %551), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[22]/BatchNorm2d[bn1]\n",
      "  %1057 : Float(1, 256, 4, 4) = onnx::Relu(%1056), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[22]/ReLU[relu]\n",
      "  %1058 : Float(1, 256, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1057, %553), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[22]/Conv2d[conv2]\n",
      "  %1059 : Float(1, 256, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%1058, %554, %555, %556, %557), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[22]/BatchNorm2d[bn2]\n",
      "  %1060 : Float(1, 256, 4, 4) = onnx::Relu(%1059), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[22]/ReLU[relu]\n",
      "  %1061 : Float(1, 1024, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1060, %559), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[22]/Conv2d[conv3]\n",
      "  %1062 : Float(1, 1024, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%1061, %560, %561, %562, %563), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[22]/BatchNorm2d[bn3]\n",
      "  %1063 : Float(1, 1024, 4, 4) = onnx::Add(%1062, %1054), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[22]\n",
      "  %1064 : Float(1, 1024, 4, 4) = onnx::Relu(%1063), scope: DynamicUnetWide/Sequential/Sequential[6]/Bottleneck[22]/ReLU[relu]\n",
      "  %1065 : Float(1, 512, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1064, %565), scope: DynamicUnetWide/Sequential/Sequential[7]/Bottleneck[0]/Conv2d[conv1]\n",
      "  %1066 : Float(1, 512, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%1065, %566, %567, %568, %569), scope: DynamicUnetWide/Sequential/Sequential[7]/Bottleneck[0]/BatchNorm2d[bn1]\n",
      "  %1067 : Float(1, 512, 4, 4) = onnx::Relu(%1066), scope: DynamicUnetWide/Sequential/Sequential[7]/Bottleneck[0]/ReLU[relu]\n",
      "  %1068 : Float(1, 512, 2, 2) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2]](%1067, %571), scope: DynamicUnetWide/Sequential/Sequential[7]/Bottleneck[0]/Conv2d[conv2]\n",
      "  %1069 : Float(1, 512, 2, 2) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%1068, %572, %573, %574, %575), scope: DynamicUnetWide/Sequential/Sequential[7]/Bottleneck[0]/BatchNorm2d[bn2]\n",
      "  %1070 : Float(1, 512, 2, 2) = onnx::Relu(%1069), scope: DynamicUnetWide/Sequential/Sequential[7]/Bottleneck[0]/ReLU[relu]\n",
      "  %1071 : Float(1, 2048, 2, 2) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1070, %577), scope: DynamicUnetWide/Sequential/Sequential[7]/Bottleneck[0]/Conv2d[conv3]\n",
      "  %1072 : Float(1, 2048, 2, 2) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%1071, %578, %579, %580, %581), scope: DynamicUnetWide/Sequential/Sequential[7]/Bottleneck[0]/BatchNorm2d[bn3]\n",
      "  %1073 : Float(1, 2048, 2, 2) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[2, 2]](%1064, %583), scope: DynamicUnetWide/Sequential/Sequential[7]/Bottleneck[0]/Sequential[downsample]/Conv2d[0]\n",
      "  %1074 : Float(1, 2048, 2, 2) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%1073, %584, %585, %586, %587), scope: DynamicUnetWide/Sequential/Sequential[7]/Bottleneck[0]/Sequential[downsample]/BatchNorm2d[1]\n",
      "  %1075 : Float(1, 2048, 2, 2) = onnx::Add(%1072, %1074), scope: DynamicUnetWide/Sequential/Sequential[7]/Bottleneck[0]\n",
      "  %1076 : Float(1, 2048, 2, 2) = onnx::Relu(%1075), scope: DynamicUnetWide/Sequential/Sequential[7]/Bottleneck[0]/ReLU[relu]\n",
      "  %1077 : Float(1, 512, 2, 2) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1076, %589), scope: DynamicUnetWide/Sequential/Sequential[7]/Bottleneck[1]/Conv2d[conv1]\n",
      "  %1078 : Float(1, 512, 2, 2) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%1077, %590, %591, %592, %593), scope: DynamicUnetWide/Sequential/Sequential[7]/Bottleneck[1]/BatchNorm2d[bn1]\n",
      "  %1079 : Float(1, 512, 2, 2) = onnx::Relu(%1078), scope: DynamicUnetWide/Sequential/Sequential[7]/Bottleneck[1]/ReLU[relu]\n",
      "  %1080 : Float(1, 512, 2, 2) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1079, %595), scope: DynamicUnetWide/Sequential/Sequential[7]/Bottleneck[1]/Conv2d[conv2]\n",
      "  %1081 : Float(1, 512, 2, 2) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%1080, %596, %597, %598, %599), scope: DynamicUnetWide/Sequential/Sequential[7]/Bottleneck[1]/BatchNorm2d[bn2]\n",
      "  %1082 : Float(1, 512, 2, 2) = onnx::Relu(%1081), scope: DynamicUnetWide/Sequential/Sequential[7]/Bottleneck[1]/ReLU[relu]\n",
      "  %1083 : Float(1, 2048, 2, 2) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1082, %601), scope: DynamicUnetWide/Sequential/Sequential[7]/Bottleneck[1]/Conv2d[conv3]\n",
      "  %1084 : Float(1, 2048, 2, 2) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%1083, %602, %603, %604, %605), scope: DynamicUnetWide/Sequential/Sequential[7]/Bottleneck[1]/BatchNorm2d[bn3]\n",
      "  %1085 : Float(1, 2048, 2, 2) = onnx::Add(%1084, %1076), scope: DynamicUnetWide/Sequential/Sequential[7]/Bottleneck[1]\n",
      "  %1086 : Float(1, 2048, 2, 2) = onnx::Relu(%1085), scope: DynamicUnetWide/Sequential/Sequential[7]/Bottleneck[1]/ReLU[relu]\n",
      "  %1087 : Float(1, 512, 2, 2) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1086, %607), scope: DynamicUnetWide/Sequential/Sequential[7]/Bottleneck[2]/Conv2d[conv1]\n",
      "  %1088 : Float(1, 512, 2, 2) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%1087, %608, %609, %610, %611), scope: DynamicUnetWide/Sequential/Sequential[7]/Bottleneck[2]/BatchNorm2d[bn1]\n",
      "  %1089 : Float(1, 512, 2, 2) = onnx::Relu(%1088), scope: DynamicUnetWide/Sequential/Sequential[7]/Bottleneck[2]/ReLU[relu]\n",
      "  %1090 : Float(1, 512, 2, 2) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1089, %613), scope: DynamicUnetWide/Sequential/Sequential[7]/Bottleneck[2]/Conv2d[conv2]\n",
      "  %1091 : Float(1, 512, 2, 2) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%1090, %614, %615, %616, %617), scope: DynamicUnetWide/Sequential/Sequential[7]/Bottleneck[2]/BatchNorm2d[bn2]\n",
      "  %1092 : Float(1, 512, 2, 2) = onnx::Relu(%1091), scope: DynamicUnetWide/Sequential/Sequential[7]/Bottleneck[2]/ReLU[relu]\n",
      "  %1093 : Float(1, 2048, 2, 2) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1092, %619), scope: DynamicUnetWide/Sequential/Sequential[7]/Bottleneck[2]/Conv2d[conv3]\n",
      "  %1094 : Float(1, 2048, 2, 2) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%1093, %620, %621, %622, %623), scope: DynamicUnetWide/Sequential/Sequential[7]/Bottleneck[2]/BatchNorm2d[bn3]\n",
      "  %1095 : Float(1, 2048, 2, 2) = onnx::Add(%1094, %1086), scope: DynamicUnetWide/Sequential/Sequential[7]/Bottleneck[2]\n",
      "  %1096 : Float(1, 2048, 2, 2) = onnx::Relu(%1095), scope: DynamicUnetWide/Sequential/Sequential[7]/Bottleneck[2]/ReLU[relu]\n",
      "  %1097 : Float(1, 2048, 2, 2) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%1096, %625, %626, %627, %628), scope: DynamicUnetWide/BatchNorm2d\n",
      "  %1098 : Float(1, 2048, 2, 2) = onnx::Relu(%1097), scope: DynamicUnetWide/ReLU\n",
      "  %1099 : Long() = onnx::Constant[value={0}](), scope: DynamicUnetWide/Sequential/Sequential[0]\n",
      "  %1100 : Tensor = onnx::Shape(%weight.1), scope: DynamicUnetWide/Sequential/Sequential[0]\n",
      "  %1101 : Long() = onnx::Gather[axis=0](%1100, %1099), scope: DynamicUnetWide/Sequential/Sequential[0]\n",
      "  %1102 : Long() = onnx::Constant[value={-1}](), scope: DynamicUnetWide/Sequential/Sequential[0]\n",
      "  %1103 : Tensor = onnx::Unsqueeze[axes=[0]](%1101)\n",
      "  %1104 : Tensor = onnx::Unsqueeze[axes=[0]](%1102)\n",
      "  %1105 : Tensor = onnx::Concat[axis=0](%1103, %1104)\n",
      "  %1106 : Float(4096, 18432) = aten::reshape(%weight.1, %1105), scope: DynamicUnetWide/Sequential/Sequential[0]\n",
      "  %1107 : Float(4096) = aten::mv(%1106, %632), scope: DynamicUnetWide/Sequential/Sequential[0]\n",
      "  %1108 : Float() = aten::dot(%631, %1107), scope: DynamicUnetWide/Sequential/Sequential[0]\n",
      "  %1109 : Float(4096, 2048, 3, 3) = onnx::Div(%weight.1, %1108), scope: DynamicUnetWide/Sequential/Sequential[0]\n",
      "  %1110 : Float(1, 4096, 2, 2) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1098, %1109), scope: DynamicUnetWide/Sequential/Sequential[0]/Conv2d[0]\n",
      "  %1111 : Float(1, 4096, 2, 2) = onnx::Relu(%1110), scope: DynamicUnetWide/Sequential/Sequential[0]/ReLU[1]\n",
      "  %1112 : Float(1, 4096, 2, 2) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%1111, %633, %634, %635, %636), scope: DynamicUnetWide/Sequential/Sequential[0]/BatchNorm2d[2]\n",
      "  %1113 : Long() = onnx::Constant[value={0}](), scope: DynamicUnetWide/Sequential/Sequential[1]\n",
      "  %1114 : Tensor = onnx::Shape(%weight.2), scope: DynamicUnetWide/Sequential/Sequential[1]\n",
      "  %1115 : Long() = onnx::Gather[axis=0](%1114, %1113), scope: DynamicUnetWide/Sequential/Sequential[1]\n",
      "  %1116 : Long() = onnx::Constant[value={-1}](), scope: DynamicUnetWide/Sequential/Sequential[1]\n",
      "  %1117 : Tensor = onnx::Unsqueeze[axes=[0]](%1115)\n",
      "  %1118 : Tensor = onnx::Unsqueeze[axes=[0]](%1116)\n",
      "  %1119 : Tensor = onnx::Concat[axis=0](%1117, %1118)\n",
      "  %1120 : Float(2048, 36864) = aten::reshape(%weight.2, %1119), scope: DynamicUnetWide/Sequential/Sequential[1]\n",
      "  %1121 : Float(2048) = aten::mv(%1120, %640), scope: DynamicUnetWide/Sequential/Sequential[1]\n",
      "  %1122 : Float() = aten::dot(%639, %1121), scope: DynamicUnetWide/Sequential/Sequential[1]\n",
      "  %1123 : Float(2048, 4096, 3, 3) = onnx::Div(%weight.2, %1122), scope: DynamicUnetWide/Sequential/Sequential[1]\n",
      "  %1124 : Float(1, 2048, 2, 2) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1112, %1123), scope: DynamicUnetWide/Sequential/Sequential[1]/Conv2d[0]\n",
      "  %1125 : Float(1, 2048, 2, 2) = onnx::Relu(%1124), scope: DynamicUnetWide/Sequential/Sequential[1]/ReLU[1]\n",
      "  %1126 : Float(1, 2048, 2, 2) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%1125, %641, %642, %643, %644), scope: DynamicUnetWide/Sequential/Sequential[1]/BatchNorm2d[2]\n",
      "  %1127 : Long() = onnx::Constant[value={0}](), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/Sequential[conv]\n",
      "  %1128 : Tensor = onnx::Shape(%weight.3), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/Sequential[conv]\n",
      "  %1129 : Long() = onnx::Gather[axis=0](%1128, %1127), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/Sequential[conv]\n",
      "  %1130 : Long() = onnx::Constant[value={-1}](), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/Sequential[conv]\n",
      "  %1131 : Tensor = onnx::Unsqueeze[axes=[0]](%1129)\n",
      "  %1132 : Tensor = onnx::Unsqueeze[axes=[0]](%1130)\n",
      "  %1133 : Tensor = onnx::Concat[axis=0](%1131, %1132)\n",
      "  %1134 : Float(2048, 2048) = aten::reshape(%weight.3, %1133), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/Sequential[conv]\n",
      "  %1135 : Float(2048) = aten::mv(%1134, %648), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/Sequential[conv]\n",
      "  %1136 : Float() = aten::dot(%647, %1135), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/Sequential[conv]\n",
      "  %1137 : Float(2048, 2048, 1, 1) = onnx::Div(%weight.3, %1136), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/Sequential[conv]\n",
      "  %1138 : Float(1, 2048, 2, 2) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1126, %1137), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/Sequential[conv]/Conv2d[0]\n",
      "  %1139 : Float(1, 2048, 2, 2) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%1138, %649, %650, %651, %652), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/Sequential[conv]/BatchNorm2d[1]\n",
      "  %1140 : Float(1, 2048, 2, 2) = onnx::Relu(%1139), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/ReLU[relu]\n",
      "  %1141 : Tensor = onnx::Constant[value=  -1    2    2  512    2    2 [ CPULongType{6} ]](), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/PixelShuffle[shuf]\n",
      "  %1142 : Tensor = onnx::Reshape(%1140, %1141), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/PixelShuffle[shuf]\n",
      "  %1143 : Tensor = onnx::Transpose[perm=[0, 1, 4, 2, 5, 3]](%1142), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/PixelShuffle[shuf]\n",
      "  %1144 : Tensor = onnx::Constant[value=  -1  512    4    4 [ CPULongType{4} ]](), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/PixelShuffle[shuf]\n",
      "  %1145 : Float(1, 512, 4, 4) = onnx::Reshape(%1143, %1144), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/PixelShuffle[shuf]\n",
      "  %1146 : Float(1, 512, 5, 5) = onnx::Pad[mode=\"edge\", pads=[0, 0, 1, 1, 0, 0, 0, 0]](%1145), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/ReplicationPad2d[pad]\n",
      "  %1147 : Tensor = onnx::Pad[mode=\"constant\", pads=[0, 0, 0, 0, 0, 0, 0, 0], value=0](%1146), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/AvgPool2d[blur]\n",
      "  %1148 : Float(1, 512, 4, 4) = onnx::AveragePool[kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[1, 1]](%1147), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/AvgPool2d[blur]\n",
      "  %1149 : Float(1, 1024, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%1064, %654, %655, %656, %657), scope: DynamicUnetWide/UnetBlockWide/BatchNorm2d[bn]\n",
      "  %1150 : Float(1, 1536, 4, 4) = onnx::Concat[axis=1](%1148, %1149), scope: DynamicUnetWide/UnetBlockWide\n",
      "  %1151 : Float(1, 1536, 4, 4) = onnx::Relu(%1150), scope: DynamicUnetWide/UnetBlockWide/ReLU[relu]\n",
      "  %1152 : Long() = onnx::Constant[value={0}](), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]\n",
      "  %1153 : Tensor = onnx::Shape(%weight.4), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]\n",
      "  %1154 : Long() = onnx::Gather[axis=0](%1153, %1152), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]\n",
      "  %1155 : Long() = onnx::Constant[value={-1}](), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]\n",
      "  %1156 : Tensor = onnx::Unsqueeze[axes=[0]](%1154)\n",
      "  %1157 : Tensor = onnx::Unsqueeze[axes=[0]](%1155)\n",
      "  %1158 : Tensor = onnx::Concat[axis=0](%1156, %1157)\n",
      "  %1159 : Float(512, 13824) = aten::reshape(%weight.4, %1158), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]\n",
      "  %1160 : Float(512) = aten::mv(%1159, %661), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]\n",
      "  %1161 : Float() = aten::dot(%660, %1160), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]\n",
      "  %1162 : Float(512, 1536, 3, 3) = onnx::Div(%weight.4, %1161), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]\n",
      "  %1163 : Float(1, 512, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1151, %1162), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]/Conv2d[0]\n",
      "  %1164 : Float(1, 512, 4, 4) = onnx::Relu(%1163), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]/ReLU[1]\n",
      "  %1165 : Float(1, 512, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%1164, %662, %663, %664, %665), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]/BatchNorm2d[2]\n",
      "  %1166 : Long() = onnx::Constant[value={0}](), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/Sequential[conv]\n",
      "  %1167 : Tensor = onnx::Shape(%weight.5), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/Sequential[conv]\n",
      "  %1168 : Long() = onnx::Gather[axis=0](%1167, %1166), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/Sequential[conv]\n",
      "  %1169 : Long() = onnx::Constant[value={-1}](), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/Sequential[conv]\n",
      "  %1170 : Tensor = onnx::Unsqueeze[axes=[0]](%1168)\n",
      "  %1171 : Tensor = onnx::Unsqueeze[axes=[0]](%1169)\n",
      "  %1172 : Tensor = onnx::Concat[axis=0](%1170, %1171)\n",
      "  %1173 : Float(2048, 512) = aten::reshape(%weight.5, %1172), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/Sequential[conv]\n",
      "  %1174 : Float(2048) = aten::mv(%1173, %669), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/Sequential[conv]\n",
      "  %1175 : Float() = aten::dot(%668, %1174), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/Sequential[conv]\n",
      "  %1176 : Float(2048, 512, 1, 1) = onnx::Div(%weight.5, %1175), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/Sequential[conv]\n",
      "  %1177 : Float(1, 2048, 4, 4) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1165, %1176), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/Sequential[conv]/Conv2d[0]\n",
      "  %1178 : Float(1, 2048, 4, 4) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%1177, %670, %671, %672, %673), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/Sequential[conv]/BatchNorm2d[1]\n",
      "  %1179 : Float(1, 2048, 4, 4) = onnx::Relu(%1178), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/ReLU[relu]\n",
      "  %1180 : Tensor = onnx::Constant[value=  -1    2    2  512    4    4 [ CPULongType{6} ]](), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/PixelShuffle[shuf]\n",
      "  %1181 : Tensor = onnx::Reshape(%1179, %1180), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/PixelShuffle[shuf]\n",
      "  %1182 : Tensor = onnx::Transpose[perm=[0, 1, 4, 2, 5, 3]](%1181), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/PixelShuffle[shuf]\n",
      "  %1183 : Tensor = onnx::Constant[value=  -1  512    8    8 [ CPULongType{4} ]](), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/PixelShuffle[shuf]\n",
      "  %1184 : Float(1, 512, 8, 8) = onnx::Reshape(%1182, %1183), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/PixelShuffle[shuf]\n",
      "  %1185 : Float(1, 512, 9, 9) = onnx::Pad[mode=\"edge\", pads=[0, 0, 1, 1, 0, 0, 0, 0]](%1184), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/ReplicationPad2d[pad]\n",
      "  %1186 : Tensor = onnx::Pad[mode=\"constant\", pads=[0, 0, 0, 0, 0, 0, 0, 0], value=0](%1185), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/AvgPool2d[blur]\n",
      "  %1187 : Float(1, 512, 8, 8) = onnx::AveragePool[kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[1, 1]](%1186), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/AvgPool2d[blur]\n",
      "  %1188 : Float(1, 512, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%832, %675, %676, %677, %678), scope: DynamicUnetWide/UnetBlockWide/BatchNorm2d[bn]\n",
      "  %1189 : Float(1, 1024, 8, 8) = onnx::Concat[axis=1](%1187, %1188), scope: DynamicUnetWide/UnetBlockWide\n",
      "  %1190 : Float(1, 1024, 8, 8) = onnx::Relu(%1189), scope: DynamicUnetWide/UnetBlockWide/ReLU[relu]\n",
      "  %1191 : Long() = onnx::Constant[value={0}](), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]\n",
      "  %1192 : Tensor = onnx::Shape(%weight.6), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]\n",
      "  %1193 : Long() = onnx::Gather[axis=0](%1192, %1191), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]\n",
      "  %1194 : Long() = onnx::Constant[value={-1}](), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]\n",
      "  %1195 : Tensor = onnx::Unsqueeze[axes=[0]](%1193)\n",
      "  %1196 : Tensor = onnx::Unsqueeze[axes=[0]](%1194)\n",
      "  %1197 : Tensor = onnx::Concat[axis=0](%1195, %1196)\n",
      "  %1198 : Float(512, 9216) = aten::reshape(%weight.6, %1197), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]\n",
      "  %1199 : Float(512) = aten::mv(%1198, %682), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]\n",
      "  %1200 : Float() = aten::dot(%681, %1199), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]\n",
      "  %1201 : Float(512, 1024, 3, 3) = onnx::Div(%weight.6, %1200), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]\n",
      "  %1202 : Float(1, 512, 8, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1190, %1201), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]/Conv2d[0]\n",
      "  %1203 : Float(1, 512, 8, 8) = onnx::Relu(%1202), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]/ReLU[1]\n",
      "  %1204 : Float(1, 512, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%1203, %683, %684, %685, %686), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]/BatchNorm2d[2]\n",
      "  %1205 : Long() = onnx::Constant[value={0}](), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]/SelfAttention[3]\n",
      "  %1206 : Tensor = onnx::Shape(%1204), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]/SelfAttention[3]\n",
      "  %1207 : Long() = onnx::Gather[axis=0](%1206, %1205), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]/SelfAttention[3]\n",
      "  %1208 : Long() = onnx::Constant[value={1}](), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]/SelfAttention[3]\n",
      "  %1209 : Tensor = onnx::Shape(%1204), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]/SelfAttention[3]\n",
      "  %1210 : Long() = onnx::Gather[axis=0](%1209, %1208), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]/SelfAttention[3]\n",
      "  %1211 : Long() = onnx::Constant[value={2}](), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]/SelfAttention[3]\n",
      "  %1212 : Tensor = onnx::Shape(%1204), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]/SelfAttention[3]\n",
      "  %1213 : Long() = onnx::Gather[axis=0](%1212, %1211), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]/SelfAttention[3]\n",
      "  %1214 : Long() = onnx::Constant[value={3}](), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]/SelfAttention[3]\n",
      "  %1215 : Tensor = onnx::Shape(%1204), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]/SelfAttention[3]\n",
      "  %1216 : Long() = onnx::Gather[axis=0](%1215, %1214), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]/SelfAttention[3]\n",
      "  %1217 : Long() = onnx::Constant[value={-1}](), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]/SelfAttention[3]\n",
      "  %1218 : Tensor = onnx::Unsqueeze[axes=[0]](%1207)\n",
      "  %1219 : Tensor = onnx::Unsqueeze[axes=[0]](%1210)\n",
      "  %1220 : Tensor = onnx::Unsqueeze[axes=[0]](%1217)\n",
      "  %1221 : Tensor = onnx::Concat[axis=0](%1218, %1219, %1220)\n",
      "  %1222 : Float(1, 512, 64) = onnx::Reshape(%1204, %1221), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]/SelfAttention[3]\n",
      "  %1223 : Long() = onnx::Constant[value={0}](), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]/SelfAttention[3]\n",
      "  %1224 : Tensor = onnx::Shape(%weight.7), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]/SelfAttention[3]\n",
      "  %1225 : Long() = onnx::Gather[axis=0](%1224, %1223), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]/SelfAttention[3]\n",
      "  %1226 : Long() = onnx::Constant[value={-1}](), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]/SelfAttention[3]\n",
      "  %1227 : Tensor = onnx::Unsqueeze[axes=[0]](%1225)\n",
      "  %1228 : Tensor = onnx::Unsqueeze[axes=[0]](%1226)\n",
      "  %1229 : Tensor = onnx::Concat[axis=0](%1227, %1228)\n",
      "  %1230 : Float(64, 512) = aten::reshape(%weight.7, %1229), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]/SelfAttention[3]\n",
      "  %1231 : Float(64) = aten::mv(%1230, %691), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]/SelfAttention[3]\n",
      "  %1232 : Float() = aten::dot(%690, %1231), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]/SelfAttention[3]\n",
      "  %1233 : Float(64, 512, 1) = onnx::Div(%weight.7, %1232), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]/SelfAttention[3]\n",
      "  %1234 : Float(1, 64, 64) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1]](%1222, %1233), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]/SelfAttention[3]/Conv1d[query]\n",
      "  %1235 : Long() = onnx::Constant[value={0}](), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]/SelfAttention[3]\n",
      "  %1236 : Tensor = onnx::Shape(%weight.8), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]/SelfAttention[3]\n",
      "  %1237 : Long() = onnx::Gather[axis=0](%1236, %1235), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]/SelfAttention[3]\n",
      "  %1238 : Long() = onnx::Constant[value={-1}](), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]/SelfAttention[3]\n",
      "  %1239 : Tensor = onnx::Unsqueeze[axes=[0]](%1237)\n",
      "  %1240 : Tensor = onnx::Unsqueeze[axes=[0]](%1238)\n",
      "  %1241 : Tensor = onnx::Concat[axis=0](%1239, %1240)\n",
      "  %1242 : Float(64, 512) = aten::reshape(%weight.8, %1241), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]/SelfAttention[3]\n",
      "  %1243 : Float(64) = aten::mv(%1242, %694), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]/SelfAttention[3]\n",
      "  %1244 : Float() = aten::dot(%693, %1243), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]/SelfAttention[3]\n",
      "  %1245 : Float(64, 512, 1) = onnx::Div(%weight.8, %1244), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]/SelfAttention[3]\n",
      "  %1246 : Float(1, 64, 64) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1]](%1222, %1245), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]/SelfAttention[3]/Conv1d[key]\n",
      "  %1247 : Long() = onnx::Constant[value={0}](), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]/SelfAttention[3]\n",
      "  %1248 : Tensor = onnx::Shape(%weight.9), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]/SelfAttention[3]\n",
      "  %1249 : Long() = onnx::Gather[axis=0](%1248, %1247), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]/SelfAttention[3]\n",
      "  %1250 : Long() = onnx::Constant[value={-1}](), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]/SelfAttention[3]\n",
      "  %1251 : Tensor = onnx::Unsqueeze[axes=[0]](%1249)\n",
      "  %1252 : Tensor = onnx::Unsqueeze[axes=[0]](%1250)\n",
      "  %1253 : Tensor = onnx::Concat[axis=0](%1251, %1252)\n",
      "  %1254 : Float(512, 512) = aten::reshape(%weight.9, %1253), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]/SelfAttention[3]\n",
      "  %1255 : Float(512) = aten::mv(%1254, %697), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]/SelfAttention[3]\n",
      "  %1256 : Float() = aten::dot(%696, %1255), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]/SelfAttention[3]\n",
      "  %1257 : Float(512, 512, 1) = onnx::Div(%weight.9, %1256), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]/SelfAttention[3]\n",
      "  %1258 : Float(1, 512, 64) = onnx::Conv[dilations=[1], group=1, kernel_shape=[1], pads=[0, 0], strides=[1]](%1222, %1257), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]/SelfAttention[3]/Conv1d[value]\n",
      "  %1259 : Float(1, 64, 64) = onnx::Transpose[perm=[0, 2, 1]](%1234), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]/SelfAttention[3]\n",
      "  %1260 : Float(1, 64, 64) = onnx::MatMul(%1259, %1246), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]/SelfAttention[3]\n",
      "  %1261 : Long() = onnx::Constant[value={1}](), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]/SelfAttention[3]\n",
      "  %1262 : Float(1, 64, 64) = aten::softmax(%1260, %1261), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]/SelfAttention[3]\n",
      "  %1263 : Float(1, 512, 64) = onnx::MatMul(%1258, %1262), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]/SelfAttention[3]\n",
      "  %1264 : Float(1, 512, 64) = onnx::Mul(%688, %1263), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]/SelfAttention[3]\n",
      "  %1265 : Float(1, 512, 64) = onnx::Add(%1264, %1222), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]/SelfAttention[3]\n",
      "  %1266 : Tensor = onnx::Unsqueeze[axes=[0]](%1207)\n",
      "  %1267 : Tensor = onnx::Unsqueeze[axes=[0]](%1210)\n",
      "  %1268 : Tensor = onnx::Unsqueeze[axes=[0]](%1213)\n",
      "  %1269 : Tensor = onnx::Unsqueeze[axes=[0]](%1216)\n",
      "  %1270 : Tensor = onnx::Concat[axis=0](%1266, %1267, %1268, %1269)\n",
      "  %1271 : Float(1, 512, 8, 8) = onnx::Reshape(%1265, %1270), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]/SelfAttention[3]\n",
      "  %1272 : Long() = onnx::Constant[value={0}](), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/Sequential[conv]\n",
      "  %1273 : Tensor = onnx::Shape(%weight.10), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/Sequential[conv]\n",
      "  %1274 : Long() = onnx::Gather[axis=0](%1273, %1272), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/Sequential[conv]\n",
      "  %1275 : Long() = onnx::Constant[value={-1}](), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/Sequential[conv]\n",
      "  %1276 : Tensor = onnx::Unsqueeze[axes=[0]](%1274)\n",
      "  %1277 : Tensor = onnx::Unsqueeze[axes=[0]](%1275)\n",
      "  %1278 : Tensor = onnx::Concat[axis=0](%1276, %1277)\n",
      "  %1279 : Float(2048, 512) = aten::reshape(%weight.10, %1278), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/Sequential[conv]\n",
      "  %1280 : Float(2048) = aten::mv(%1279, %700), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/Sequential[conv]\n",
      "  %1281 : Float() = aten::dot(%699, %1280), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/Sequential[conv]\n",
      "  %1282 : Float(2048, 512, 1, 1) = onnx::Div(%weight.10, %1281), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/Sequential[conv]\n",
      "  %1283 : Float(1, 2048, 8, 8) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1271, %1282), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/Sequential[conv]/Conv2d[0]\n",
      "  %1284 : Float(1, 2048, 8, 8) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%1283, %701, %702, %703, %704), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/Sequential[conv]/BatchNorm2d[1]\n",
      "  %1285 : Float(1, 2048, 8, 8) = onnx::Relu(%1284), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/ReLU[relu]\n",
      "  %1286 : Tensor = onnx::Constant[value=  -1    2    2  512    8    8 [ CPULongType{6} ]](), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/PixelShuffle[shuf]\n",
      "  %1287 : Tensor = onnx::Reshape(%1285, %1286), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/PixelShuffle[shuf]\n",
      "  %1288 : Tensor = onnx::Transpose[perm=[0, 1, 4, 2, 5, 3]](%1287), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/PixelShuffle[shuf]\n",
      "  %1289 : Tensor = onnx::Constant[value=  -1  512   16   16 [ CPULongType{4} ]](), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/PixelShuffle[shuf]\n",
      "  %1290 : Float(1, 512, 16, 16) = onnx::Reshape(%1288, %1289), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/PixelShuffle[shuf]\n",
      "  %1291 : Float(1, 512, 17, 17) = onnx::Pad[mode=\"edge\", pads=[0, 0, 1, 1, 0, 0, 0, 0]](%1290), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/ReplicationPad2d[pad]\n",
      "  %1292 : Tensor = onnx::Pad[mode=\"constant\", pads=[0, 0, 0, 0, 0, 0, 0, 0], value=0](%1291), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/AvgPool2d[blur]\n",
      "  %1293 : Float(1, 512, 16, 16) = onnx::AveragePool[kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[1, 1]](%1292), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/AvgPool2d[blur]\n",
      "  %1294 : Float(1, 256, 16, 16) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%790, %706, %707, %708, %709), scope: DynamicUnetWide/UnetBlockWide/BatchNorm2d[bn]\n",
      "  %1295 : Float(1, 768, 16, 16) = onnx::Concat[axis=1](%1293, %1294), scope: DynamicUnetWide/UnetBlockWide\n",
      "  %1296 : Float(1, 768, 16, 16) = onnx::Relu(%1295), scope: DynamicUnetWide/UnetBlockWide/ReLU[relu]\n",
      "  %1297 : Long() = onnx::Constant[value={0}](), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]\n",
      "  %1298 : Tensor = onnx::Shape(%weight.11), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]\n",
      "  %1299 : Long() = onnx::Gather[axis=0](%1298, %1297), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]\n",
      "  %1300 : Long() = onnx::Constant[value={-1}](), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]\n",
      "  %1301 : Tensor = onnx::Unsqueeze[axes=[0]](%1299)\n",
      "  %1302 : Tensor = onnx::Unsqueeze[axes=[0]](%1300)\n",
      "  %1303 : Tensor = onnx::Concat[axis=0](%1301, %1302)\n",
      "  %1304 : Float(512, 6912) = aten::reshape(%weight.11, %1303), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]\n",
      "  %1305 : Float(512) = aten::mv(%1304, %713), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]\n",
      "  %1306 : Float() = aten::dot(%712, %1305), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]\n",
      "  %1307 : Float(512, 768, 3, 3) = onnx::Div(%weight.11, %1306), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]\n",
      "  %1308 : Float(1, 512, 16, 16) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1296, %1307), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]/Conv2d[0]\n",
      "  %1309 : Float(1, 512, 16, 16) = onnx::Relu(%1308), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]/ReLU[1]\n",
      "  %1310 : Float(1, 512, 16, 16) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%1309, %714, %715, %716, %717), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]/BatchNorm2d[2]\n",
      "  %1311 : Long() = onnx::Constant[value={0}](), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/Sequential[conv]\n",
      "  %1312 : Tensor = onnx::Shape(%weight.12), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/Sequential[conv]\n",
      "  %1313 : Long() = onnx::Gather[axis=0](%1312, %1311), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/Sequential[conv]\n",
      "  %1314 : Long() = onnx::Constant[value={-1}](), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/Sequential[conv]\n",
      "  %1315 : Tensor = onnx::Unsqueeze[axes=[0]](%1313)\n",
      "  %1316 : Tensor = onnx::Unsqueeze[axes=[0]](%1314)\n",
      "  %1317 : Tensor = onnx::Concat[axis=0](%1315, %1316)\n",
      "  %1318 : Float(1024, 512) = aten::reshape(%weight.12, %1317), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/Sequential[conv]\n",
      "  %1319 : Float(1024) = aten::mv(%1318, %721), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/Sequential[conv]\n",
      "  %1320 : Float() = aten::dot(%720, %1319), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/Sequential[conv]\n",
      "  %1321 : Float(1024, 512, 1, 1) = onnx::Div(%weight.12, %1320), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/Sequential[conv]\n",
      "  %1322 : Float(1, 1024, 16, 16) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1310, %1321), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/Sequential[conv]/Conv2d[0]\n",
      "  %1323 : Float(1, 1024, 16, 16) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%1322, %722, %723, %724, %725), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/Sequential[conv]/BatchNorm2d[1]\n",
      "  %1324 : Float(1, 1024, 16, 16) = onnx::Relu(%1323), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/ReLU[relu]\n",
      "  %1325 : Tensor = onnx::Constant[value=  -1    2    2  256   16   16 [ CPULongType{6} ]](), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/PixelShuffle[shuf]\n",
      "  %1326 : Tensor = onnx::Reshape(%1324, %1325), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/PixelShuffle[shuf]\n",
      "  %1327 : Tensor = onnx::Transpose[perm=[0, 1, 4, 2, 5, 3]](%1326), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/PixelShuffle[shuf]\n",
      "  %1328 : Tensor = onnx::Constant[value=  -1  256   32   32 [ CPULongType{4} ]](), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/PixelShuffle[shuf]\n",
      "  %1329 : Float(1, 256, 32, 32) = onnx::Reshape(%1327, %1328), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/PixelShuffle[shuf]\n",
      "  %1330 : Float(1, 256, 33, 33) = onnx::Pad[mode=\"edge\", pads=[0, 0, 1, 1, 0, 0, 0, 0]](%1329), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/ReplicationPad2d[pad]\n",
      "  %1331 : Tensor = onnx::Pad[mode=\"constant\", pads=[0, 0, 0, 0, 0, 0, 0, 0], value=0](%1330), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/AvgPool2d[blur]\n",
      "  %1332 : Float(1, 256, 32, 32) = onnx::AveragePool[kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[1, 1]](%1331), scope: DynamicUnetWide/UnetBlockWide/CustomPixelShuffle_ICNR[shuf]/AvgPool2d[blur]\n",
      "  %1333 : Float(1, 64, 32, 32) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%757, %727, %728, %729, %730), scope: DynamicUnetWide/UnetBlockWide/BatchNorm2d[bn]\n",
      "  %1334 : Float(1, 320, 32, 32) = onnx::Concat[axis=1](%1332, %1333), scope: DynamicUnetWide/UnetBlockWide\n",
      "  %1335 : Float(1, 320, 32, 32) = onnx::Relu(%1334), scope: DynamicUnetWide/UnetBlockWide/ReLU[relu]\n",
      "  %1336 : Long() = onnx::Constant[value={0}](), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]\n",
      "  %1337 : Tensor = onnx::Shape(%weight.13), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]\n",
      "  %1338 : Long() = onnx::Gather[axis=0](%1337, %1336), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]\n",
      "  %1339 : Long() = onnx::Constant[value={-1}](), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]\n",
      "  %1340 : Tensor = onnx::Unsqueeze[axes=[0]](%1338)\n",
      "  %1341 : Tensor = onnx::Unsqueeze[axes=[0]](%1339)\n",
      "  %1342 : Tensor = onnx::Concat[axis=0](%1340, %1341)\n",
      "  %1343 : Float(256, 2880) = aten::reshape(%weight.13, %1342), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]\n",
      "  %1344 : Float(256) = aten::mv(%1343, %734), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]\n",
      "  %1345 : Float() = aten::dot(%733, %1344), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]\n",
      "  %1346 : Float(256, 320, 3, 3) = onnx::Div(%weight.13, %1345), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]\n",
      "  %1347 : Float(1, 256, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1335, %1346), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]/Conv2d[0]\n",
      "  %1348 : Float(1, 256, 32, 32) = onnx::Relu(%1347), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]/ReLU[1]\n",
      "  %1349 : Float(1, 256, 32, 32) = onnx::BatchNormalization[epsilon=1e-05, momentum=1](%1348, %735, %736, %737, %738), scope: DynamicUnetWide/UnetBlockWide/Sequential[conv]/BatchNorm2d[2]\n",
      "  %1350 : Float(1024, 256, 1, 1) = onnx::ATen[dim=0, operator=\"_weight_norm\"](%742, %741), scope: DynamicUnetWide/PixelShuffle_ICNR/Sequential[conv]\n",
      "  %1351 : Float(1, 1024, 32, 32) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1349, %1350, %740), scope: DynamicUnetWide/PixelShuffle_ICNR/Sequential[conv]/Conv2d[0]\n",
      "  %1352 : Float(1, 1024, 32, 32) = onnx::Relu(%1351), scope: DynamicUnetWide/PixelShuffle_ICNR/ReLU[relu]\n",
      "  %1353 : Tensor = onnx::Constant[value=  -1    2    2  256   32   32 [ CPULongType{6} ]](), scope: DynamicUnetWide/PixelShuffle_ICNR/PixelShuffle[shuf]\n",
      "  %1354 : Tensor = onnx::Reshape(%1352, %1353), scope: DynamicUnetWide/PixelShuffle_ICNR/PixelShuffle[shuf]\n",
      "  %1355 : Tensor = onnx::Transpose[perm=[0, 1, 4, 2, 5, 3]](%1354), scope: DynamicUnetWide/PixelShuffle_ICNR/PixelShuffle[shuf]\n",
      "  %1356 : Tensor = onnx::Constant[value=  -1  256   64   64 [ CPULongType{4} ]](), scope: DynamicUnetWide/PixelShuffle_ICNR/PixelShuffle[shuf]\n",
      "  %1357 : Float(1, 256, 64, 64) = onnx::Reshape(%1355, %1356), scope: DynamicUnetWide/PixelShuffle_ICNR/PixelShuffle[shuf]\n",
      "  %1358 : Float(1, 256, 65, 65) = onnx::Pad[mode=\"edge\", pads=[0, 0, 1, 1, 0, 0, 0, 0]](%1357), scope: DynamicUnetWide/PixelShuffle_ICNR/ReplicationPad2d[pad]\n",
      "  %1359 : Tensor = onnx::Pad[mode=\"constant\", pads=[0, 0, 0, 0, 0, 0, 0, 0], value=0](%1358), scope: DynamicUnetWide/PixelShuffle_ICNR/AvgPool2d[blur]\n",
      "  %1360 : Float(1, 256, 64, 64) = onnx::AveragePool[kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[1, 1]](%1359), scope: DynamicUnetWide/PixelShuffle_ICNR/AvgPool2d[blur]\n",
      "  %1361 : Float(1, 259, 64, 64) = onnx::Concat[axis=1](%1360, %0), scope: DynamicUnetWide/MergeLayer\n",
      "  %1362 : Long() = onnx::Constant[value={0}](), scope: DynamicUnetWide/SequentialEx/Sequential\n",
      "  %1363 : Tensor = onnx::Shape(%weight.14), scope: DynamicUnetWide/SequentialEx/Sequential\n",
      "  %1364 : Long() = onnx::Gather[axis=0](%1363, %1362), scope: DynamicUnetWide/SequentialEx/Sequential\n",
      "  %1365 : Long() = onnx::Constant[value={-1}](), scope: DynamicUnetWide/SequentialEx/Sequential\n",
      "  %1366 : Tensor = onnx::Unsqueeze[axes=[0]](%1364)\n",
      "  %1367 : Tensor = onnx::Unsqueeze[axes=[0]](%1365)\n",
      "  %1368 : Tensor = onnx::Concat[axis=0](%1366, %1367)\n",
      "  %1369 : Float(259, 2331) = aten::reshape(%weight.14, %1368), scope: DynamicUnetWide/SequentialEx/Sequential\n",
      "  %1370 : Float(259) = aten::mv(%1369, %746), scope: DynamicUnetWide/SequentialEx/Sequential\n",
      "  %1371 : Float() = aten::dot(%745, %1370), scope: DynamicUnetWide/SequentialEx/Sequential\n",
      "  %1372 : Float(259, 259, 3, 3) = onnx::Div(%weight.14, %1371), scope: DynamicUnetWide/SequentialEx/Sequential\n",
      "  %1373 : Float(1, 259, 64, 64) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1361, %1372, %743), scope: DynamicUnetWide/SequentialEx/Sequential/Conv2d[0]\n",
      "  %1374 : Float(1, 259, 64, 64) = onnx::Relu(%1373), scope: DynamicUnetWide/SequentialEx/Sequential/ReLU[1]\n",
      "  %1375 : Long() = onnx::Constant[value={0}](), scope: DynamicUnetWide/SequentialEx/Sequential\n",
      "  %1376 : Tensor = onnx::Shape(%weight.15), scope: DynamicUnetWide/SequentialEx/Sequential\n",
      "  %1377 : Long() = onnx::Gather[axis=0](%1376, %1375), scope: DynamicUnetWide/SequentialEx/Sequential\n",
      "  %1378 : Long() = onnx::Constant[value={-1}](), scope: DynamicUnetWide/SequentialEx/Sequential\n",
      "  %1379 : Tensor = onnx::Unsqueeze[axes=[0]](%1377)\n",
      "  %1380 : Tensor = onnx::Unsqueeze[axes=[0]](%1378)\n",
      "  %1381 : Tensor = onnx::Concat[axis=0](%1379, %1380)\n",
      "  %1382 : Float(259, 2331) = aten::reshape(%weight.15, %1381), scope: DynamicUnetWide/SequentialEx/Sequential\n",
      "  %1383 : Float(259) = aten::mv(%1382, %750), scope: DynamicUnetWide/SequentialEx/Sequential\n",
      "  %1384 : Float() = aten::dot(%749, %1383), scope: DynamicUnetWide/SequentialEx/Sequential\n",
      "  %1385 : Float(259, 259, 3, 3) = onnx::Div(%weight.15, %1384), scope: DynamicUnetWide/SequentialEx/Sequential\n",
      "  %1386 : Float(1, 259, 64, 64) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1]](%1374, %1385, %747), scope: DynamicUnetWide/SequentialEx/Sequential/Conv2d[0]\n",
      "  %1387 : Float(1, 259, 64, 64) = onnx::Relu(%1386), scope: DynamicUnetWide/SequentialEx/Sequential/ReLU[1]\n",
      "  %1388 : Float(1, 259, 64, 64) = onnx::Add(%1387, %1361), scope: DynamicUnetWide/SequentialEx/MergeLayer\n",
      "  %1389 : Long() = onnx::Constant[value={0}](), scope: DynamicUnetWide/Sequential\n",
      "  %1390 : Tensor = onnx::Shape(%weight), scope: DynamicUnetWide/Sequential\n",
      "  %1391 : Long() = onnx::Gather[axis=0](%1390, %1389), scope: DynamicUnetWide/Sequential\n",
      "  %1392 : Long() = onnx::Constant[value={-1}](), scope: DynamicUnetWide/Sequential\n",
      "  %1393 : Tensor = onnx::Unsqueeze[axes=[0]](%1391)\n",
      "  %1394 : Tensor = onnx::Unsqueeze[axes=[0]](%1392)\n",
      "  %1395 : Tensor = onnx::Concat[axis=0](%1393, %1394)\n",
      "  %1396 : Float(3, 259) = aten::reshape(%weight, %1395), scope: DynamicUnetWide/Sequential\n",
      "  %1397 : Float(3) = aten::mv(%1396, %754), scope: DynamicUnetWide/Sequential\n",
      "  %1398 : Float() = aten::dot(%753, %1397), scope: DynamicUnetWide/Sequential\n",
      "  %1399 : Float(3, 259, 1, 1) = onnx::Div(%weight, %1398), scope: DynamicUnetWide/Sequential\n",
      "  %1400 : Float(1, 3, 64, 64) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[1, 1]](%1388, %1399, %751), scope: DynamicUnetWide/Sequential/Conv2d[0]\n",
      "  %1401 : Float(1, 3, 64, 64) = onnx::Sigmoid(%1400), scope: DynamicUnetWide/SigmoidRange\n",
      "  %1402 : Tensor = onnx::Constant[value={6}]()\n",
      "  %1403 : Tensor = onnx::Mul(%1401, %1402)\n",
      "  %1404 : Tensor = onnx::Constant[value={-3}]()\n",
      "  %1405 : Float(1, 3, 64, 64) = onnx::Add(%1403, %1404)\n",
      "  return (%1405);\n",
      "}\n",
      "\n",
      "Your model fails onnx too, please report to onnx team\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dmv/miniconda3/envs/deoldify/lib/python3.7/threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/dmv/miniconda3/envs/deoldify/lib/python3.7/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/dmv/miniconda3/envs/deoldify/lib/python3.7/site-packages/fastai/callbacks/tensorboard.py\", line 227, in _queue_processor\n",
      "    request.write()\n",
      "  File \"/home/dmv/miniconda3/envs/deoldify/lib/python3.7/site-packages/fastai/callbacks/tensorboard.py\", line 417, in write\n",
      "    self.tbwriter.add_graph(model=self.model, input_to_model=self.input_to_model)\n",
      "  File \"/home/dmv/miniconda3/envs/deoldify/lib/python3.7/site-packages/tensorboardX/writer.py\", line 566, in add_graph\n",
      "    self.file_writer.add_graph(graph(model, input_to_model, verbose))\n",
      "  File \"/home/dmv/miniconda3/envs/deoldify/lib/python3.7/site-packages/tensorboardX/writer.py\", line 107, in add_graph\n",
      "    graph = graph_profile[0]\n",
      "TypeError: 'GraphDef' object is not subscriptable\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 0: Sizes of tensors must match except in dimension 1. Got 1 and 44 in dimension 0 at /opt/conda/conda-bld/pytorch_1549636813070/work/aten/src/THC/generic/THCTensorMath.cu:83",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_141742/3642294116.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_one_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpct_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/deoldify/lib/python3.7/site-packages/fastai/train.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(learn, cyc_len, max_lr, moms, div_factor, pct_start, final_div, wd, callbacks, tot_epochs, start_epoch)\u001b[0m\n\u001b[1;32m     20\u001b[0m     callbacks.append(OneCycleScheduler(learn, max_lr, moms=moms, div_factor=div_factor, pct_start=pct_start,\n\u001b[1;32m     21\u001b[0m                                        final_div=final_div, tot_epochs=tot_epochs, start_epoch=start_epoch))\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcyc_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlr_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mLearner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_div\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deoldify/lib/python3.7/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callbacks\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_callbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deoldify/lib/python3.7/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, learn, callbacks, metrics)\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deoldify/lib/python3.7/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mxb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_loss_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deoldify/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deoldify/lib/python3.7/site-packages/fastai/layers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m             \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m             \u001b[0mnres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m             \u001b[0;31m# We have to remove res.orig to avoid hanging refs and therefore memory leaks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deoldify/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DeOldify/deoldify/unet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, up_in)\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mssh\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mup_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0mup_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mup_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'nearest'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0mcat_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mup_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: invalid argument 0: Sizes of tensors must match except in dimension 1. Got 1 and 44 in dimension 0 at /opt/conda/conda-bld/pytorch_1549636813070/work/aten/src/THC/generic/THCTensorMath.cu:83"
     ]
    }
   ],
   "source": [
    "learn_gen.fit_one_cycle(1, pct_start=0.8, max_lr=slice(1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_gen.save(pre_gen_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_gen.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_gen.fit_one_cycle(1, pct_start=pct_start,  max_lr=slice(3e-7, 3e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_gen.save(pre_gen_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 128px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=11\n",
    "sz=128\n",
    "keep_pct=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_gen.data = get_data(sz=sz, bs=bs, keep_pct=keep_pct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_gen.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_gen.fit_one_cycle(1, pct_start=pct_start, max_lr=slice(1e-7,1e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_gen.save(pre_gen_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 192px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=4\n",
    "sz=192\n",
    "keep_pct=0.50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_gen.data = get_data(sz=sz, bs=bs, keep_pct=keep_pct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_gen.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_gen.fit_one_cycle(1, pct_start=pct_start, max_lr=slice(5e-8,5e-5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_gen.save(pre_gen_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeatable GAN Cycle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE\n",
    "Best results so far have been based on repeating the cycle below a few times (about 5-8?), until diminishing returns are hit (no improvement in image quality).  Each time you repeat the cycle, you want to increment that old_checkpoint_num by 1 so that new check points don't overwrite the old.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_checkpoint_num = 0\n",
    "checkpoint_num = old_checkpoint_num + 1\n",
    "gen_old_checkpoint_name = gen_name + '_' + str(old_checkpoint_num)\n",
    "gen_new_checkpoint_name = gen_name + '_' + str(checkpoint_num)\n",
    "crit_old_checkpoint_name = crit_name + '_' + str(old_checkpoint_num)\n",
    "crit_new_checkpoint_name= crit_name + '_' + str(checkpoint_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Generated Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=4\n",
    "sz=192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_gen = gen_learner_wide(data=data_gen, gen_loss=FeatureLoss(), nf_factor=nf_factor).load(gen_old_checkpoint_name, with_opt=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_gen_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrain Critic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Only need full pretraining of critic when starting from scratch.  Otherwise, just finetune!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if old_checkpoint_num == 0:\n",
    "    bs=64\n",
    "    sz=128\n",
    "    learn_gen=None\n",
    "    gc.collect()\n",
    "    data_crit = get_crit_data([name_gen, 'test'], bs=bs, sz=sz)\n",
    "    data_crit.show_batch(rows=3, ds_type=DatasetType.Train, imgsize=3)\n",
    "    learn_critic = colorize_crit_learner(data=data_crit, nf=256)\n",
    "    learn_critic.callback_fns.append(partial(LearnerTensorboardWriter, base_dir=TENSORBOARD_PATH, name='CriticPre'))\n",
    "    learn_critic.fit_one_cycle(6, 1e-3)\n",
    "    learn_critic.save(crit_old_checkpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=16\n",
    "sz=192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_crit = get_crit_data([name_gen, 'test'], bs=bs, sz=sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_crit.show_batch(rows=3, ds_type=DatasetType.Train, imgsize=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_critic = colorize_crit_learner(data=data_crit, nf=256).load(crit_old_checkpoint_name, with_opt=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_critic.callback_fns.append(partial(LearnerTensorboardWriter, base_dir=TENSORBOARD_PATH, name='CriticPre'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_critic.fit_one_cycle(4, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_critic.save(crit_new_checkpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_crit=None\n",
    "learn_gen=None\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=2e-5\n",
    "sz=192\n",
    "bs=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_crit = get_crit_data([name_gen, 'test'], bs=bs, sz=sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_crit = colorize_crit_learner(data=data_crit, nf=256).load(crit_new_checkpoint_name, with_opt=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_gen = gen_learner_wide(data=data_gen, gen_loss=FeatureLoss(), nf_factor=nf_factor).load(gen_old_checkpoint_name, with_opt=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "switcher = partial(AdaptiveGANSwitcher, critic_thresh=0.65)\n",
    "learn = GANLearner.from_learners(learn_gen, learn_crit, weights_gen=(1.0,1.5), show_img=False, switcher=switcher,\n",
    "                                 opt_func=partial(optim.Adam, betas=(0.,0.9)), wd=1e-3)\n",
    "learn.callback_fns.append(partial(GANDiscriminativeLR, mult_lr=5.))\n",
    "learn.callback_fns.append(partial(GANTensorboardWriter, base_dir=TENSORBOARD_PATH, name='GanLearner', visual_iters=100))\n",
    "learn.callback_fns.append(partial(GANSaveCallback, learn_gen=learn_gen, filename=gen_new_checkpoint_name, save_iters=100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instructions:  \n",
    "Find the checkpoint just before where glitches start to be introduced.  This is all very new so you may need to play around with just how far you go here with keep_pct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.data = get_data(sz=sz, bs=bs, keep_pct=0.03)\n",
    "learn_gen.freeze_to(-1)\n",
    "learn.fit(1,lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
